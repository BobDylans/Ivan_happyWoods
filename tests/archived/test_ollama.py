"""
æµ‹è¯• Ollama OpenAI-Compatible API
"""
import httpx
import json

async def test_ollama_chat():
    url = "http://localhost:11434/v1/chat/completions"
    
    payload = {
        "model": "qwen3:4b",
        "messages": [
            {"role": "user", "content": "ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±"}
        ],
        "stream": False
    }
    
    print("ğŸ“¡ æµ‹è¯• Ollama å¯¹è¯æ¥å£...")
    print(f"URL: {url}")
    print(f"æ¨¡å‹: {payload['model']}")
    print(f"æ¶ˆæ¯: {payload['messages'][0]['content']}")
    print("\n" + "="*60)
    
    async with httpx.AsyncClient(timeout=30) as client:
        try:
            response = await client.post(
                url,
                json=payload,
                headers={"Content-Type": "application/json"}
            )
            
            if response.status_code == 200:
                result = response.json()
                print("\nâœ… è°ƒç”¨æˆåŠŸï¼")
                print(f"æ¨¡å‹: {result['model']}")
                print(f"å›å¤: {result['choices'][0]['message']['content']}")
                print(f"Token ä½¿ç”¨: {result.get('usage', {})}")
                return True
            else:
                print(f"\nâŒ è°ƒç”¨å¤±è´¥ï¼çŠ¶æ€ç : {response.status_code}")
                print(f"å“åº”: {response.text}")
                return False
                
        except Exception as e:
            print(f"\nâŒ å¼‚å¸¸: {e}")
            return False

async def test_ollama_stream():
    url = "http://localhost:11434/v1/chat/completions"
    
    payload = {
        "model": "qwen3:4b",
        "messages": [
            {"role": "user", "content": "æ•°åˆ°5"}
        ],
        "stream": True
    }
    
    print("\n\nğŸ“¡ æµ‹è¯• Ollama æµå¼æ¥å£...")
    print(f"URL: {url}")
    print(f"æ¨¡å‹: {payload['model']}")
    print("\nå›å¤: ", end="", flush=True)
    
    async with httpx.AsyncClient(timeout=30) as client:
        try:
            async with client.stream(
                "POST",
                url,
                json=payload,
                headers={"Content-Type": "application/json"}
            ) as response:
                if response.status_code == 200:
                    async for line in response.aiter_lines():
                        if line.startswith("data: "):
                            data = line[6:]
                            if data == "[DONE]":
                                break
                            try:
                                chunk = json.loads(data)
                                content = chunk['choices'][0]['delta'].get('content', '')
                                if content:
                                    print(content, end="", flush=True)
                            except:
                                pass
                    print("\n\nâœ… æµå¼è°ƒç”¨æˆåŠŸï¼")
                    return True
                else:
                    print(f"\nâŒ æµå¼è°ƒç”¨å¤±è´¥ï¼çŠ¶æ€ç : {response.status_code}")
                    return False
                    
        except Exception as e:
            print(f"\nâŒ å¼‚å¸¸: {e}")
            return False

if __name__ == "__main__":
    import asyncio
    
    async def main():
        # æµ‹è¯•æ™®é€šå¯¹è¯
        success1 = await test_ollama_chat()
        
        # æµ‹è¯•æµå¼å¯¹è¯
        success2 = await test_ollama_stream()
        
        print("\n" + "="*60)
        if success1 and success2:
            print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å¯ä»¥åˆ‡æ¢åˆ° Ollamaï¼")
        else:
            print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥é…ç½®")
    
    asyncio.run(main())
