# RAG ç³»ç»Ÿæ¶æ„åˆ†æ

ğŸ“… **æ—¥æœŸ**: 2025-11-08  
ğŸ¯ **ç›®æ ‡**: å…¨é¢åˆ†æé¡¹ç›®ä¸­ RAG (Retrieval-Augmented Generation) ç³»ç»Ÿçš„é›†æˆæ¶æ„

---

## ğŸ“‹ ç›®å½•

1. [æ¦‚è¿°](#æ¦‚è¿°)
2. [æ ¸å¿ƒç»„ä»¶](#æ ¸å¿ƒç»„ä»¶)
3. [æ•°æ®æµ](#æ•°æ®æµ)
4. [é›†æˆç‚¹](#é›†æˆç‚¹)
5. [é…ç½®ç®¡ç†](#é…ç½®ç®¡ç†)
6. [æ•°æ®åº“è®¾è®¡](#æ•°æ®åº“è®¾è®¡)
7. [API æ¥å£](#api-æ¥å£)
8. [Agent é›†æˆ](#agent-é›†æˆ)
9. [å‘é‡éªŒè¯](#å‘é‡éªŒè¯)
10. [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)

---

## æ¦‚è¿°

### ä»€ä¹ˆæ˜¯ RAGï¼Ÿ

RAG (Retrieval-Augmented Generation) æ˜¯ä¸€ç§ç»“åˆäº†**æ£€ç´¢**å’Œ**ç”Ÿæˆ**çš„ AI æŠ€æœ¯ï¼š

1. **æ£€ç´¢ (Retrieval)**: ä»çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³æ–‡æ¡£ç‰‡æ®µ
2. **å¢å¼º (Augmented)**: å°†æ£€ç´¢åˆ°çš„å†…å®¹ä½œä¸ºä¸Šä¸‹æ–‡
3. **ç”Ÿæˆ (Generation)**: LLM åŸºäºä¸Šä¸‹æ–‡ç”Ÿæˆæ›´å‡†ç¡®çš„å›ç­”

### é¡¹ç›®ä¸­çš„ RAG å®šä½

```
ç”¨æˆ·é—®é¢˜ 
    â†“
[RAG æ£€ç´¢] â†’ ä»å‘é‡æ•°æ®åº“æ£€ç´¢ç›¸å…³ç‰‡æ®µ
    â†“
[ä¸Šä¸‹æ–‡å¢å¼º] â†’ å°†ç‰‡æ®µæ³¨å…¥ LLM prompt
    â†“
[LLM ç”Ÿæˆ] â†’ åŸºäºçŸ¥è¯†åº“ç”Ÿæˆå›ç­”
    â†“
ç”¨æˆ·å¾—åˆ°å‡†ç¡®ç­”æ¡ˆ
```

### å…³é”®ç‰¹æ€§

- âœ… **Per-User Collections**: æ¯ä¸ªç”¨æˆ·ç‹¬ç«‹çš„çŸ¥è¯†åº“
- âœ… **å¤šæ ¼å¼æ”¯æŒ**: MD, PDF, DOCX, TXT
- âœ… **å‘é‡æ£€ç´¢**: åŸºäº Qdrant çš„é«˜æ•ˆç›¸ä¼¼åº¦æœç´¢
- âœ… **åµŒå…¥æœåŠ¡**: å…¼å®¹ OpenAI Embedding API
- âœ… **å…ƒæ•°æ®è¿½è¸ª**: PostgreSQL å­˜å‚¨æ–‡æ¡£å’Œå—çš„å…ƒæ•°æ®
- âœ… **åŠ¨æ€é›†æˆ**: è¿è¡Œæ—¶æ— ç¼é›†æˆåˆ°å¯¹è¯æµç¨‹

---

## æ ¸å¿ƒç»„ä»¶

### 1. å››å±‚æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   API Layer                         â”‚
â”‚  â€¢ /api/v1/rag/upload (ä¸Šä¼ æ–‡æ¡£)                     â”‚
â”‚  â€¢ /api/v1/rag/user/upload (ç”¨æˆ·ä¸Šä¼ )                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                Service Layer                        â”‚
â”‚  â€¢ RAGService (æœåŠ¡é—¨é¢)                            â”‚
â”‚  â€¢ Ingestion (æ–‡æ¡£å¤„ç†)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                Storage Layer                        â”‚
â”‚  â€¢ EmbeddingClient (å‘é‡ç”Ÿæˆ)                       â”‚
â”‚  â€¢ QdrantVectorStore (å‘é‡å­˜å‚¨)                     â”‚
â”‚  â€¢ PostgreSQL (å…ƒæ•°æ®å­˜å‚¨)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                Agent Integration                    â”‚
â”‚  â€¢ _retrieve_rag_snippets() (æ£€ç´¢)                  â”‚
â”‚  â€¢ prepare_llm_messages() (æ³¨å…¥)                    â”‚
â”‚  â€¢ LLMCaller/LLMStreamer (è°ƒç”¨)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. æ¨¡å—èŒè´£

#### `src/rag/service.py` - RAG æœåŠ¡é—¨é¢

**èŒè´£**: ç»Ÿä¸€çš„ RAG æ“ä½œæ¥å£

```python
class RAGService:
    def __init__(self, config: VoiceAgentConfig)
    
    # æ ¸å¿ƒæ–¹æ³•
    async def retrieve(query, user_id, corpus_id, top_k) -> List[RAGResult]
    async def ensure_collection(user_id, corpus_id, recreate)
    def resolve_collection_name(user_id, corpus_id) -> str
    def build_prompt(results: List[RAGResult]) -> str
```

**å…³é”®åŠŸèƒ½**:
- åè°ƒ EmbeddingClient å’Œ QdrantVectorStore
- å¤„ç† per-user collection é€»è¾‘
- æ ¼å¼åŒ–æ£€ç´¢ç»“æœä¸º LLM å¯ç”¨çš„ prompt

#### `src/rag/embedding_client.py` - åµŒå…¥å‘é‡ç”Ÿæˆ

**èŒè´£**: è°ƒç”¨ Embedding API ç”Ÿæˆå‘é‡

```python
class EmbeddingClient:
    def __init__(self, base_url, api_key, model, timeout)
    
    async def embed_texts(texts: List[str]) -> List[List[float]]
```

**ç‰¹ç‚¹**:
- å…¼å®¹ OpenAI Embedding API
- æ‰¹é‡å¤„ç†æ–‡æœ¬
- è‡ªåŠ¨æ„å»º `/v1/embeddings` ç«¯ç‚¹

#### `src/rag/qdrant_store.py` - å‘é‡æ•°æ®åº“

**èŒè´£**: ç®¡ç† Qdrant å‘é‡å­˜å‚¨

```python
class QdrantVectorStore:
    def __init__(self, config: RAGConfig, collection_name)
    
    # é›†åˆç®¡ç†
    async def ensure_collection(vector_size, recreate)
    
    # å‘é‡æ“ä½œ
    async def upsert_chunks(chunks: List[DocumentChunk])
    async def search(query_embedding, top_k, min_score) -> List[RetrievedChunk]
```

**éªŒè¯æœºåˆ¶**:
- âœ… å‘é‡ç»´åº¦æ£€æŸ¥
- âœ… æ•°å€¼æœ‰æ•ˆæ€§éªŒè¯ (NaN/Inf)
- âœ… ç±»å‹å®‰å…¨æ£€æŸ¥
- âœ… æ‰¹é‡å¤„ç†æ—¥å¿—

#### `src/rag/ingestion.py` - æ–‡æ¡£æ‘„å–

**èŒè´£**: å¤„ç†æ–‡æ¡£ä¸Šä¼ å’Œå‘é‡åŒ–

```python
async def ingest_files(
    config,
    files,
    user_id,
    corpus_name,
    collection_name,
    db_session
) -> IngestionResult
```

**å¤„ç†æµç¨‹**:
1. è§£ææ–‡æ¡£ (PDF/DOCX/MD/TXT)
2. æ–‡æœ¬åˆ‡å— (chunk_text)
3. æ‰¹é‡ç”ŸæˆåµŒå…¥ (_flush_batch)
4. å­˜å‚¨å‘é‡åˆ° Qdrant
5. è®°å½•å…ƒæ•°æ®åˆ° PostgreSQL

**æ”¯æŒçš„æ–‡ä»¶ç±»å‹**:
```python
SUPPORTED_SUFFIXES = {
    ".md", ".markdown", ".mdx",
    ".txt",
    ".pdf",
    ".docx"
}
```

---

## æ•°æ®æµ

### 1. æ–‡æ¡£ä¸Šä¼ æµç¨‹

```
ç”¨æˆ·ä¸Šä¼ æ–‡æ¡£
    â†“
[API Layer] /api/v1/rag/user/upload
    â”œâ”€ éªŒè¯ç”¨æˆ· ID
    â”œâ”€ æ£€æŸ¥æ–‡ä»¶ç±»å‹å’Œå¤§å°
    â””â”€ ä¿å­˜ä¸´æ—¶æ–‡ä»¶
    â†“
[Ingestion] ingest_files()
    â”œâ”€ è§£ææ–‡æ¡£å†…å®¹
    â”œâ”€ æ–‡æœ¬åˆ‡å— (300 chars, 60 overlap)
    â””â”€ ç”Ÿæˆ DocumentChunk[]
    â†“
[Embedding] embed_texts()
    â”œâ”€ æ‰¹é‡è°ƒç”¨ Embedding API
    â””â”€ è¿”å›å‘é‡ List[List[float]]
    â†“
[Validation] _flush_batch()
    â”œâ”€ éªŒè¯å‘é‡ç»´åº¦
    â”œâ”€ æ£€æŸ¥æ•°å€¼æœ‰æ•ˆæ€§
    â””â”€ èµ‹å€¼ chunk.embedding
    â†“
[Qdrant] upsert_chunks()
    â”œâ”€ åˆ›å»º PointStruct
    â””â”€ æ‰¹é‡å†™å…¥ Qdrant
    â†“
[PostgreSQL] RAGRepository
    â”œâ”€ åˆ›å»º RAGCorpus è®°å½•
    â”œâ”€ åˆ›å»º RAGDocument è®°å½•
    â””â”€ åˆ›å»º RAGChunk è®°å½•
    â†“
è¿”å› IngestionResult
    {
        processed_files: 1,
        stored_chunks: 23,
        failed_files: [],
        skipped_files: []
    }
```

### 2. å¯¹è¯æ£€ç´¢æµç¨‹

```
ç”¨æˆ·æé—®: "ä»€ä¹ˆæ˜¯ RAGï¼Ÿ"
    â†“
[Agent] process_message_stream()
    â”œâ”€ åˆ›å»º AgentState
    â””â”€ è°ƒç”¨ LangGraph workflow
    â†“
[Node] call_llm() / stream_llm_call()
    â†“
[Step 1] _retrieve_rag_snippets(state)
    â”œâ”€ æ£€æŸ¥ RAG æ˜¯å¦å¯ç”¨
    â”œâ”€ è§£æ user_id å’Œ corpus_id
    â”œâ”€ è°ƒç”¨ embedding_client.embed_texts([query])
    â”œâ”€ è°ƒç”¨ qdrant_store.search(query_vector)
    â””â”€ è¿”å› List[RAGResult]
    â†“
[Step 2] prepare_llm_messages(state, external_history)
    â”œâ”€ åŠ è½½ç³»ç»Ÿ prompt
    â”œâ”€ åŠ è½½å¯¹è¯å†å²
    â””â”€ è¿”å› messages[]
    â†“
[Step 3] æ³¨å…¥ RAG ä¸Šä¸‹æ–‡
    â”œâ”€ rag_service.build_prompt(rag_results)
    â”œâ”€ åˆ›å»º system message
    â””â”€ æ’å…¥åˆ° messages (åœ¨æœ€åä¸€æ¡ user message ä¹‹å‰)
    â†“
[Step 4] è°ƒç”¨ LLM
    â”œâ”€ POST {base_url}/v1/chat/completions
    â”œâ”€ æºå¸¦å¢å¼ºåçš„ messages
    â””â”€ è¿”å›åŸºäºçŸ¥è¯†åº“çš„å›ç­”
    â†“
ç”¨æˆ·æ”¶åˆ°å‡†ç¡®ç­”æ¡ˆ
```

### 3. Collection å‘½åé€»è¾‘

```python
# é…ç½®
config.rag.per_user_collections = True
config.rag.collection = "knowledge_base"
config.rag.collection_name_template = "{collection}_{user_id}_{corpus_id}"

# è§£æè¿‡ç¨‹
user_id = "user_12345"
corpus_id = "tech_docs"

# 1. æ¸…ç†å­—ç¬¦
sanitized_user = "user-12345"   # æ›¿æ¢éæ³•å­—ç¬¦
sanitized_corpus = "tech-docs"

# 2. æ ¼å¼åŒ–æ¨¡æ¿
collection_name = "knowledge_base_user-12345_tech-docs"

# 3. è½¬æ¢å°å†™
final_name = "knowledge_base_user-12345_tech-docs"

# ç»“æœ: æ¯ä¸ªç”¨æˆ·çš„æ¯ä¸ª corpus æœ‰ç‹¬ç«‹çš„ Qdrant collection
```

---

## é›†æˆç‚¹

### 1. Agent é›†æˆ (`src/agent/`)

#### LLMCaller (`nodes/llm_caller.py`)

```python
async def call_llm(self, state: AgentState) -> AgentState:
    # ğŸ” Step 1: æ£€ç´¢ RAG ç‰‡æ®µ
    rag_results = await self._retrieve_rag_snippets(state)
    
    # ğŸ“ Step 2: å‡†å¤‡æ¶ˆæ¯å†å²
    messages = prepare_llm_messages(state, external_history)
    
    # ğŸ’‰ Step 3: æ³¨å…¥ RAG ä¸Šä¸‹æ–‡
    if rag_results and self._rag_service:
        rag_prompt = self._rag_service.build_prompt(rag_results)
        system_message = {"role": "system", "content": rag_prompt}
        messages.insert(len(messages) - 1, system_message)
    
    # ğŸ¤– Step 4: è°ƒç”¨ LLM
    response = await llm_client.chat.completions.create(
        model=model,
        messages=messages,
        tools=tools_schema
    )
```

#### LLMStreamer (`nodes/llm_streamer.py`)

**æµå¼è°ƒç”¨ç‰ˆæœ¬**ï¼Œé€»è¾‘ç›¸åŒï¼š
- åŒæ ·æ‰§è¡Œ 4 æ­¥æµç¨‹
- ä½¿ç”¨ `stream=True`
- é€ token è¿”å›ç»“æœ

#### AgentNodesBase (`nodes/base.py`)

**å…±äº«çš„ RAG æ£€ç´¢é€»è¾‘**:

```python
async def _retrieve_rag_snippets(self, state: AgentState) -> List[Any]:
    # 1. æ£€æŸ¥ RAG æ˜¯å¦å¯ç”¨
    if not self._rag_service or not self.config.rag.enabled:
        return []
    
    # 2. è·å–æŸ¥è¯¢æ–‡æœ¬
    query = state.get("user_input", "")
    
    # 3. è§£æç”¨æˆ·å’Œè¯­æ–™åº“ ID
    user_id = state.get("user_id")
    corpus_id = state.get("active_corpus_id") or config.rag.default_corpus_name
    
    # 4. è§£æ collection åç§°
    resolved_collection = self._rag_service.resolve_collection_name(
        user_id=user_id,
        corpus_id=corpus_id
    )
    
    # 5. æ‰§è¡Œæ£€ç´¢
    results = await self._rag_service.retrieve(
        query,
        user_id=user_id,
        corpus_id=corpus_id,
        collection_name=resolved_collection
    )
    
    # 6. å­˜å‚¨åˆ° state
    state["rag_snippets"] = [
        {
            "text": item.text,
            "score": item.score,
            "source": item.source,
            "metadata": item.metadata
        }
        for item in results
    ]
    
    return results
```

### 2. API é›†æˆ (`src/api/routes.py`)

#### ä¸Šä¼ æ¥å£

```python
@rag_router.post("/user/upload", response_model=RAGUploadResponse)
async def upload_user_documents(
    user_id: str = Form(...),
    corpus_name: Optional[str] = Form(None),
    corpus_description: Optional[str] = Form(None),
    files: List[UploadFile] = File(...),
    config = Depends(get_config),
    db_session: AsyncSession = Depends(get_db_session)
):
    return await _handle_rag_upload(
        user_id=user_id,
        corpus_name=corpus_name,
        corpus_description=corpus_description,
        collection_name=None,
        files=files,
        config=config,
        db_session=db_session
    )
```

#### æ ¸å¿ƒå¤„ç†å‡½æ•°

```python
async def _handle_rag_upload(
    user_id: str,
    corpus_name: Optional[str],
    corpus_description: Optional[str],
    collection_name: Optional[str],
    files: List[UploadFile],
    config: VoiceAgentConfig,
    db_session: Optional[AsyncSession]
) -> RAGUploadResponse:
    # 1. éªŒè¯ RAG æ˜¯å¦å¯ç”¨
    if not config.rag.enabled:
        raise HTTPException(400, "RAG is disabled")
    
    # 2. éªŒè¯æ–‡ä»¶
    for file in files:
        if Path(file.filename).suffix.lower() not in SUPPORTED_SUFFIXES:
            raise HTTPException(400, f"Unsupported file type: {file.filename}")
    
    # 3. ä¿å­˜ä¸´æ—¶æ–‡ä»¶
    temp_dir = Path(config.rag.upload_temp_dir)
    temp_dir.mkdir(parents=True, exist_ok=True)
    saved_paths = []
    for file in files:
        temp_path = temp_dir / f"{uuid.uuid4()}_{file.filename}"
        with open(temp_path, "wb") as f:
            content = await file.read()
            f.write(content)
        saved_paths.append(temp_path)
    
    # 4. è°ƒç”¨ ingestion
    result = await ingest_files(
        config=config,
        files=saved_paths,
        user_id=user_id,
        corpus_name=corpus_name,
        corpus_description=corpus_description,
        collection_name=collection_name,
        db_session=db_session
    )
    
    # 5. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    for path in saved_paths:
        path.unlink(missing_ok=True)
    
    # 6. è¿”å›ç»“æœ
    return RAGUploadResponse(
        success=True,
        message=f"Processed {result.processed_files} files",
        processed_count=result.processed_files,
        stored_chunks=result.stored_chunks,
        failed_files=[...]
    )
```

---

## é…ç½®ç®¡ç†

### é…ç½®ç»“æ„ (`src/config/models.py`)

```python
class RAGConfig(BaseModel):
    # ğŸ”§ åŸºç¡€é…ç½®
    enabled: bool = True
    per_user_collections: bool = True
    
    # ğŸ—„ï¸ å­˜å‚¨é…ç½®
    qdrant_url: str = "http://localhost:6333"
    qdrant_api_key: Optional[str] = None
    collection: str = "default_kb"
    collection_name_template: str = "{collection}_{user_id}_{corpus_id}"
    
    # ğŸ“¦ Corpus é…ç½®
    default_corpus_name: str = "default"
    
    # ğŸ§  Embedding é…ç½®
    embed_model: str = "text-embedding-3-small"
    embed_dim: int = 1536
    
    # âœ‚ï¸ æ–‡æœ¬å¤„ç†
    chunk_size: int = 300
    chunk_overlap: int = 60
    
    # ğŸ” æ£€ç´¢é…ç½®
    top_k: int = 5
    min_score: float = 0.15
    
    # ğŸ“„ æ–‡ä»¶å¤„ç†
    doc_glob: str = "docs/**/*.md;docs/**/*.pdf;docs/**/*.docx"
    pdf_max_pages: int = 25
    docx_max_paragraphs: Optional[int] = None
    
    # ğŸ“¤ ä¸Šä¼ é…ç½®
    upload_temp_dir: str = "docs/uploads"
    max_upload_size_mb: int = 20
    ingest_batch_size: int = 16
    
    # â±ï¸ ç½‘ç»œé…ç½®
    request_timeout: int = 15
```

### ç¯å¢ƒå˜é‡è¦†ç›–

```bash
# å¯ç”¨ RAG
VOICE_AGENT_RAG__ENABLED=true

# Qdrant è¿æ¥
VOICE_AGENT_RAG__QDRANT_URL=http://localhost:6333
VOICE_AGENT_RAG__QDRANT_API_KEY=your_key

# Embedding é…ç½®
VOICE_AGENT_RAG__EMBED_MODEL=text-embedding-3-small
VOICE_AGENT_RAG__EMBED_DIM=1536

# Per-User Collections
VOICE_AGENT_RAG__PER_USER_COLLECTIONS=true
VOICE_AGENT_RAG__COLLECTION_NAME_TEMPLATE=kb_{user_id}_{corpus_id}

# æ£€ç´¢å‚æ•°
VOICE_AGENT_RAG__TOP_K=5
VOICE_AGENT_RAG__MIN_SCORE=0.15
```

---

## æ•°æ®åº“è®¾è®¡

### PostgreSQL Schema

#### 1. `rag_corpora` - è¯­æ–™åº“è¡¨

```sql
CREATE TABLE rag_corpora (
    corpus_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL REFERENCES users(user_id) ON DELETE CASCADE,
    corpus_name VARCHAR(255) NOT NULL,
    collection_name VARCHAR(255) NOT NULL UNIQUE,
    description TEXT,
    meta_data JSONB DEFAULT '{}',
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    
    CONSTRAINT uq_user_corpus UNIQUE (user_id, corpus_name)
);

CREATE INDEX idx_rag_corpora_user ON rag_corpora(user_id);
CREATE INDEX idx_rag_corpora_collection ON rag_corpora(collection_name);
```

**èŒè´£**: ç®¡ç†ç”¨æˆ·çš„æ–‡æ¡£é›†åˆ

#### 2. `rag_documents` - æ–‡æ¡£è¡¨

```sql
CREATE TABLE rag_documents (
    document_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    corpus_id UUID NOT NULL REFERENCES rag_corpora(corpus_id) ON DELETE CASCADE,
    user_id UUID NOT NULL REFERENCES users(user_id) ON DELETE CASCADE,
    source_path VARCHAR(1024),
    source_url VARCHAR(1024),
    display_name VARCHAR(255) NOT NULL,
    checksum VARCHAR(128),
    size_bytes INTEGER,
    mime_type VARCHAR(255),
    status VARCHAR(32) DEFAULT 'ACTIVE',
    ingestion_id UUID,
    meta_data JSONB DEFAULT '{}',
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

CREATE INDEX idx_rag_documents_corpus ON rag_documents(corpus_id);
CREATE INDEX idx_rag_documents_user ON rag_documents(user_id);
```

**èŒè´£**: å­˜å‚¨æ–‡æ¡£å…ƒæ•°æ®

#### 3. `rag_chunks` - æ–‡æœ¬å—è¡¨

```sql
CREATE TABLE rag_chunks (
    chunk_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    document_id UUID NOT NULL REFERENCES rag_documents(document_id) ON DELETE CASCADE,
    corpus_id UUID NOT NULL REFERENCES rag_corpora(corpus_id) ON DELETE CASCADE,
    user_id UUID NOT NULL REFERENCES users(user_id) ON DELETE CASCADE,
    point_id VARCHAR(255) NOT NULL,  -- Qdrant point ID
    chunk_index INTEGER NOT NULL,
    text_preview TEXT,
    meta_data JSONB DEFAULT '{}',
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

CREATE INDEX idx_rag_chunks_document ON rag_chunks(document_id);
CREATE INDEX idx_rag_chunks_point ON rag_chunks(point_id);
```

**èŒè´£**: è¿½è¸ª Qdrant å‘é‡ç‚¹çš„å…ƒæ•°æ®

### Qdrant Schema

#### Collection ç»“æ„

```python
{
    "name": "kb_user-12345_tech-docs",
    "vectors": {
        "size": 1536,  # å‘é‡ç»´åº¦
        "distance": "Cosine"  # ç›¸ä¼¼åº¦åº¦é‡
    }
}
```

#### Point ç»“æ„

```python
{
    "id": "550e8400-e29b-41d4-a716-446655440000",  # UUID
    "vector": [0.123, -0.456, ...],  # 1536ç»´å‘é‡
    "payload": {
        "text": "RAG æ˜¯ä¸€ç§ç»“åˆäº†æ£€ç´¢å’Œç”Ÿæˆçš„ AI æŠ€æœ¯...",
        "source": "docs/rag_intro.md",
        "source_name": "rag_intro.md",
        "source_type": "md",
        "owner_id": "user_12345",
        "corpus_id": "1",
        "collection_name": "kb_user-12345_tech-docs",
        "document_id": "doc_uuid",
        "chunk_index": 0,
        "source_display": "RAG ä»‹ç»"
    }
}
```

### æ•°æ®å…³ç³»

```
users (PostgreSQL)
  â†“ 1:N
rag_corpora (PostgreSQL)
  â”œâ”€ collection_name â†’ Qdrant Collection
  â†“ 1:N
rag_documents (PostgreSQL)
  â†“ 1:N
rag_chunks (PostgreSQL)
  â”œâ”€ point_id â†’ Qdrant Point
  â””â”€ metadata
```

---

## API æ¥å£

### 1. ä¸Šä¼ æ–‡æ¡£ (ç®¡ç†å‘˜)

```http
POST /api/v1/rag/upload
Content-Type: multipart/form-data

corpus_name=tech_docs
corpus_description=æŠ€æœ¯æ–‡æ¡£é›†åˆ
collection_name=custom_collection (å¯é€‰)
files=@file1.pdf
files=@file2.md
```

**å“åº”**:
```json
{
    "success": true,
    "message": "Successfully processed 2 files",
    "corpus_id": "1",
    "collection_name": "custom_collection",
    "processed_count": 2,
    "stored_chunks": 45,
    "results": [
        {
            "filename": "file1.pdf",
            "status": "success",
            "chunks_count": 23,
            "error": null
        },
        {
            "filename": "file2.md",
            "status": "success",
            "chunks_count": 22,
            "error": null
        }
    ]
}
```

### 2. ç”¨æˆ·ä¸Šä¼ æ–‡æ¡£

```http
POST /api/v1/rag/user/upload
Content-Type: multipart/form-data
Authorization: Bearer <token>

user_id=user_12345
corpus_name=my_notes
corpus_description=æˆ‘çš„ç¬”è®°
files=@note1.md
files=@note2.pdf
```

**å“åº”**: åŒä¸Š

### 3. å¯¹è¯ä¸­è‡ªåŠ¨æ£€ç´¢

```http
POST /api/v1/chat
Content-Type: application/json

{
    "message": "ä»€ä¹ˆæ˜¯ RAGï¼Ÿ",
    "session_id": "sess_001",
    "user_id": "user_12345",
    "stream": true
}
```

**å†…éƒ¨æµç¨‹**:
1. Agent æ¥æ”¶æ¶ˆæ¯
2. è‡ªåŠ¨è°ƒç”¨ `_retrieve_rag_snippets()`
3. æ£€ç´¢ç›¸å…³ç‰‡æ®µ
4. æ³¨å…¥åˆ° LLM prompt
5. è¿”å›å¢å¼ºåçš„å›ç­”

**å“åº”** (æµå¼):
```
data: {"type": "start", "session_id": "sess_001"}

data: {"type": "delta", "content": "RAG"}
data: {"type": "delta", "content": " æ˜¯ä¸€ç§"}
data: {"type": "delta", "content": "ç»“åˆäº†æ£€ç´¢å’Œç”Ÿæˆçš„..."}

data: {"type": "rag_context", "snippets": [...]}

data: {"type": "end", "metadata": {...}}
```

---

## Agent é›†æˆ

### 1. State å®šä¹‰ (`src/agent/state.py`)

```python
class AgentState(TypedDict):
    # ... å…¶ä»–å­—æ®µ
    
    # RAG ç›¸å…³å­—æ®µ
    rag_snippets: List[Dict[str, Any]]  # æ£€ç´¢åˆ°çš„ç‰‡æ®µ
    active_corpus_id: Optional[str]     # å½“å‰æ´»è·ƒçš„ corpus
    rag_collection: Optional[str]       # è§£æåçš„ collection åç§°
```

### 2. åˆå§‹åŒ– (`src/agent/graph.py`)

```python
class VoiceAgent:
    def __init__(self, config: VoiceAgentConfig):
        self.config = config
        self.nodes = AgentNodes(config, trace=self.trace)
        # nodes å†…éƒ¨åˆå§‹åŒ– RAGService
```

### 3. èŠ‚ç‚¹åˆå§‹åŒ– (`src/agent/nodes/base.py`)

```python
class AgentNodesBase:
    def __init__(self, config: VoiceAgentConfig, trace: TraceEmitter):
        self.config = config
        self._rag_service = None
        
        # åˆå§‹åŒ– RAG service (å¦‚æœå¯ç”¨)
        if config.rag.enabled:
            try:
                from rag.service import RAGService
                self._rag_service = RAGService(config)
                logger.info("âœ… RAG service initialized successfully")
            except Exception as e:
                logger.warning(f"âš ï¸ RAG service initialization failed: {e}")
                self._rag_service = None
```

### 4. æ£€ç´¢é›†æˆ

**æ—¶æœº**: åœ¨ `call_llm()` æˆ– `stream_llm_call()` å¼€å§‹æ—¶

```python
async def call_llm(self, state: AgentState) -> AgentState:
    # Step 1: æ£€ç´¢ RAG ç‰‡æ®µ
    rag_results = await self._retrieve_rag_snippets(state)
    # â†’ è‡ªåŠ¨å¡«å…… state["rag_snippets"]
    
    # Step 2: å‡†å¤‡æ¶ˆæ¯
    messages = prepare_llm_messages(state, external_history)
    
    # Step 3: æ³¨å…¥ RAG ä¸Šä¸‹æ–‡
    if rag_results and self._rag_service:
        rag_prompt = self._rag_service.build_prompt(rag_results)
        system_message = {"role": "system", "content": rag_prompt}
        # æ’å…¥åˆ°æœ€åä¸€æ¡ user message ä¹‹å‰
        messages.insert(len(messages) - 1, system_message)
    
    # Step 4: è°ƒç”¨ LLM (æºå¸¦å¢å¼ºçš„ä¸Šä¸‹æ–‡)
    ...
```

### 5. Prompt æ ¼å¼åŒ–

```python
def build_prompt(self, results: List[RAGResult]) -> str:
    """
    æ ¼å¼åŒ–æ£€ç´¢ç»“æœä¸º LLM prompt
    """
    if not results:
        return ""
    
    lines = [
        "ä½ å¯ä»¥å‚è€ƒä»¥ä¸‹çŸ¥è¯†ç‰‡æ®µè¿›è¡Œå›ç­”ã€‚å¦‚ä¿¡æ¯ä¸å®æ—¶äº‹å®å†²çªï¼Œè¯·ä¼˜å…ˆä½¿ç”¨æœ€æ–°äº‹å®ï¼š",
    ]
    
    for idx, item in enumerate(results, start=1):
        header = f"[{idx}] æ¥æº: {item.source or 'Unknown'} (score={item.score:.3f})"
        lines.append(header)
        lines.append(item.text.strip())
        lines.append("")
    
    return "\n".join(lines).strip()
```

**ç¤ºä¾‹è¾“å‡º**:
```
ä½ å¯ä»¥å‚è€ƒä»¥ä¸‹çŸ¥è¯†ç‰‡æ®µè¿›è¡Œå›ç­”ã€‚å¦‚ä¿¡æ¯ä¸å®æ—¶äº‹å®å†²çªï¼Œè¯·ä¼˜å…ˆä½¿ç”¨æœ€æ–°äº‹å®ï¼š

[1] æ¥æº: docs/rag_intro.md (score=0.856)
RAG (Retrieval-Augmented Generation) æ˜¯ä¸€ç§ç»“åˆäº†æ£€ç´¢å’Œç”Ÿæˆçš„ AI æŠ€æœ¯ã€‚
å®ƒé¦–å…ˆä»çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³æ–‡æ¡£ï¼Œç„¶åå°†è¿™äº›æ–‡æ¡£ä½œä¸ºä¸Šä¸‹æ–‡è¾“å…¥ç»™ LLMã€‚

[2] æ¥æº: docs/tech_overview.md (score=0.782)
RAG ç³»ç»Ÿé€šå¸¸åŒ…å«ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶ï¼šæ–‡æ¡£å­˜å‚¨ã€å‘é‡æ£€ç´¢å’Œç”Ÿæˆæ¨¡å‹ã€‚
```

---

## å‘é‡éªŒè¯

### 1. Ingestion å±‚éªŒè¯ (`_flush_batch`)

```python
async def _flush_batch(batch, embedding_client, vector_store, ...):
    # 1. éªŒè¯æ–‡æœ¬éç©º
    for idx, text in enumerate(texts):
        if not text or not text.strip():
            raise ValueError(f"Chunk {batch[idx].id} has empty text")
    
    # 2. è°ƒç”¨ Embedding API
    embeddings = await embedding_client.embed_texts(texts)
    
    # 3. éªŒè¯è¿”å›å€¼
    if not isinstance(embeddings, list):
        raise ValueError("Invalid embedding response type")
    
    if len(embeddings) != len(batch):
        raise ValueError(f"Expected {len(batch)} vectors, got {len(embeddings)}")
    
    # 4. é€ä¸ªéªŒè¯å‘é‡
    for idx, (chunk, embedding) in enumerate(zip(batch, embeddings)):
        # 4.1 éç©ºæ£€æŸ¥
        if not embedding:
            raise ValueError(f"Chunk {chunk.id} received empty embedding")
        
        # 4.2 ç±»å‹æ£€æŸ¥
        if not isinstance(embedding, list):
            raise ValueError(f"Invalid embedding type: {type(embedding)}")
        
        # 4.3 ç»´åº¦æ£€æŸ¥
        if len(embedding) != expected_dim:
            raise ValueError(
                f"Dimension mismatch: expected {expected_dim}, got {len(embedding)}"
            )
        
        # 4.4 æ•°å€¼éªŒè¯
        for i, val in enumerate(embedding):
            if not isinstance(val, (int, float)):
                raise ValueError(f"Non-numeric value at position {i}")
            if val != val:  # NaN check
                raise ValueError(f"NaN value at position {i}")
            if abs(val) == float('inf'):
                raise ValueError(f"Infinite value at position {i}")
        
        # 4.5 èµ‹å€¼
        chunk.embedding = embedding
```

### 2. Qdrant å±‚éªŒè¯ (`upsert_chunks`)

```python
async def upsert_chunks(self, chunks: Iterable[DocumentChunk], ...):
    expected_dim = self.config.embed_dim
    
    for idx, chunk in enumerate(chunks):
        # 1. ID éªŒè¯
        if not chunk.id or not isinstance(chunk.id, str):
            raise ValueError(f"Invalid chunk ID at index {idx}")
        
        # 2. æ–‡æœ¬éªŒè¯
        if not chunk.text or not isinstance(chunk.text, str):
            logger.warning(f"Chunk {chunk.id} has empty text, skipping")
            continue
        
        # 3. Embedding å­˜åœ¨æ€§
        if not chunk.embedding:
            raise ValueError(f"Chunk {chunk.id} has empty embedding")
        
        # 4. ç±»å‹éªŒè¯
        if not isinstance(chunk.embedding, list):
            raise ValueError(f"Invalid embedding type for {chunk.id}")
        
        # 5. ç»´åº¦éªŒè¯
        actual_dim = len(chunk.embedding)
        if actual_dim != expected_dim:
            raise ValueError(
                f"Chunk {chunk.id} dimension mismatch: "
                f"expected {expected_dim}, got {actual_dim}"
            )
        
        # 6. æ•°å€¼èŒƒå›´æ£€æŸ¥
        for i, val in enumerate(chunk.embedding):
            if not isinstance(val, (int, float)):
                raise ValueError(f"Non-numeric value in {chunk.id}")
            if not (-1e10 < val < 1e10):
                raise ValueError(f"Extreme value in {chunk.id}: {val}")
    
    # 7. æ‰¹é‡ upsert
    await self._client.upsert(collection_name=..., points=points)
```

### 3. éªŒè¯è¦†ç›–èŒƒå›´

| éªŒè¯é¡¹ | Ingestion | Qdrant | è¯´æ˜ |
|--------|-----------|--------|------|
| **æ–‡æœ¬éç©º** | âœ… | âœ… | é˜²æ­¢ç©ºå†…å®¹ç”Ÿæˆæ— æ•ˆå‘é‡ |
| **å‘é‡æ•°é‡** | âœ… | âŒ | API è¿”å›æ•°é‡åŒ¹é…æ£€æŸ¥ |
| **å‘é‡éç©º** | âœ… | âœ… | é˜²æ­¢ None æˆ– [] |
| **ç±»å‹æ£€æŸ¥** | âœ… | âœ… | ç¡®ä¿æ˜¯ List[float] |
| **ç»´åº¦åŒ¹é…** | âœ… | âœ… | 1536 ç»´åº¦æ£€æŸ¥ |
| **NaN/Inf** | âœ… | âŒ | é˜²æ­¢æ— æ•ˆæ•°å€¼ |
| **æå€¼æ£€æŸ¥** | âŒ | âœ… | é˜²æ­¢å¼‚å¸¸å¤§çš„æ•°å€¼ |

---

## æœ€ä½³å®è·µ

### 1. æ–‡æ¡£ä¸Šä¼ 

```python
# âœ… å¥½çš„åšæ³•
await upload_documents(
    user_id="user_12345",
    corpus_name="project_docs",
    corpus_description="é¡¹ç›®ç›¸å…³æ–‡æ¡£",
    files=[file1, file2, file3]
)

# âŒ ä¸å¥½çš„åšæ³•
# 1. ä¸æŒ‡å®š corpus_name (ä½¿ç”¨é»˜è®¤å€¼ä¸å¤Ÿè¯­ä¹‰åŒ–)
# 2. ä¸Šä¼ è¿‡å¤§æ–‡ä»¶ (è¶…è¿‡ max_upload_size_mb)
# 3. ä¸å¤„ç† failed_files (å¿½ç•¥é”™è¯¯)
```

### 2. Collection ç®¡ç†

```python
# âœ… å¯ç”¨ per-user collections
config.rag.per_user_collections = True
config.rag.collection_name_template = "kb_{user_id}_{corpus_id}"

# âœ… ä¸åŒç”¨æˆ·æ•°æ®éš”ç¦»
# user_1 â†’ kb_user-1_tech
# user_2 â†’ kb_user-2_tech

# âŒ æ‰€æœ‰ç”¨æˆ·å…±äº«ä¸€ä¸ª collection (æ•°æ®æ··æ·†)
config.rag.per_user_collections = False
```

### 3. æ£€ç´¢å‚æ•°è°ƒä¼˜

```python
# ğŸ¯ é«˜ç²¾åº¦åœºæ™¯ (æ³•å¾‹ã€åŒ»ç–—)
config.rag.top_k = 3
config.rag.min_score = 0.75  # åªè¿”å›é«˜ç›¸å…³åº¦ç»“æœ

# ğŸ¯ é€šç”¨å¯¹è¯åœºæ™¯
config.rag.top_k = 5
config.rag.min_score = 0.15  # å…è®¸ä¸€äº›å¼±ç›¸å…³ç»“æœ

# ğŸ¯ æ¢ç´¢æ€§æŸ¥è¯¢
config.rag.top_k = 10
config.rag.min_score = 0.05  # å¹¿æ³›æ£€ç´¢
```

### 4. æ–‡æœ¬åˆ‡å—ç­–ç•¥

```python
# âœ… æŠ€æœ¯æ–‡æ¡£ (ä¿ç•™å®Œæ•´è¯­ä¹‰)
chunk_size = 500
chunk_overlap = 100

# âœ… å¯¹è¯è®°å½• (è¾ƒå°å—)
chunk_size = 300
chunk_overlap = 60

# âœ… é•¿ç¯‡æ–‡ç«  (è¾ƒå¤§å—)
chunk_size = 800
chunk_overlap = 150

# âŒ è¿‡å° (è¯­ä¹‰ç¢ç‰‡åŒ–)
chunk_size = 100  # ä¸æ¨è

# âŒ è¿‡å¤§ (æ£€ç´¢ä¸ç²¾ç¡®)
chunk_size = 2000  # ä¸æ¨è
```

### 5. é”™è¯¯å¤„ç†

```python
# âœ… ä¼˜é›…é™çº§
try:
    rag_results = await _retrieve_rag_snippets(state)
except Exception as e:
    logger.warning(f"RAG retrieval failed: {e}")
    rag_results = []  # ç»§ç»­å¤„ç†ï¼Œä¸ä¸­æ–­å¯¹è¯

# âœ… è¯¦ç»†çš„é”™è¯¯æ—¥å¿—
logger.error(
    f"Failed to upsert chunks: {e}. "
    f"Batch size: {len(batch)}, "
    f"First chunk ID: {batch[0].id if batch else 'N/A'}"
)

# âŒ ç›´æ¥æŠ›å‡ºå¼‚å¸¸ (ä¸­æ–­ç”¨æˆ·å¯¹è¯)
rag_results = await _retrieve_rag_snippets(state)  # å¯èƒ½å¤±è´¥
```

### 6. æ€§èƒ½ä¼˜åŒ–

```python
# âœ… æ‰¹é‡å¤„ç†
ingest_batch_size = 16  # ä¸€æ¬¡å¤„ç† 16 ä¸ª chunks

# âœ… é€‚å½“çš„è¶…æ—¶
request_timeout = 15  # 15 ç§’

# âœ… è¿æ¥æ± 
# EmbeddingClient å’Œ QdrantClient å†…éƒ¨ç»´æŠ¤è¿æ¥æ± 

# âŒ é€ä¸ªå¤„ç† (å¤ªæ…¢)
for chunk in chunks:
    embedding = await embed_texts([chunk.text])  # ä¸é«˜æ•ˆ

# âœ… æ‰¹é‡å¤„ç†
embeddings = await embed_texts([c.text for c in chunks])
```

---

## æ€»ç»“

### æ ¸å¿ƒæ¶æ„ç‰¹ç‚¹

1. **å››å±‚åˆ†ç¦»**: API â†’ Service â†’ Storage â†’ Agent
2. **æ¨¡å—åŒ–è®¾è®¡**: æ¯ä¸ªç»„ä»¶èŒè´£å•ä¸€ï¼Œæ˜“äºæµ‹è¯•
3. **åŠ¨æ€é›†æˆ**: RAG æ£€ç´¢æ— ç¼é›†æˆåˆ°å¯¹è¯æµç¨‹
4. **æ•°æ®éš”ç¦»**: Per-user collections ä¿è¯éšç§
5. **å®¹é”™æœºåˆ¶**: å¤šå±‚éªŒè¯ + ä¼˜é›…é™çº§

### æ•°æ®æµæ€»ç»“

```
æ–‡æ¡£ä¸Šä¼  â†’ è§£æ â†’ åˆ‡å— â†’ åµŒå…¥ â†’ å­˜å‚¨ (Qdrant + PostgreSQL)
                                        â†“
ç”¨æˆ·æé—® â†’ åµŒå…¥ â†’ æ£€ç´¢ â†’ æ ¼å¼åŒ– â†’ æ³¨å…¥ prompt â†’ LLM ç”Ÿæˆ â†’ å›ç­”
```

### å…³é”®ä¼˜åŠ¿

- âœ… **å‡†ç¡®æ€§**: åŸºäºçŸ¥è¯†åº“çš„å›ç­”æ›´å¯é 
- âœ… **å¯è¿½æº¯**: æ¯ä¸ªç­”æ¡ˆéƒ½æœ‰æ¥æºå¼•ç”¨
- âœ… **å¯æ‰©å±•**: æ”¯æŒåŠ¨æ€æ·»åŠ æ–‡æ¡£
- âœ… **é«˜æ€§èƒ½**: å‘é‡æ£€ç´¢ < 100ms
- âœ… **æ˜“ç»´æŠ¤**: æ¸…æ™°çš„æ¨¡å—åˆ’åˆ†

### æŠ€æœ¯æ ˆ

| ç»„ä»¶ | æŠ€æœ¯ | ç”¨é€” |
|------|------|------|
| **å‘é‡å­˜å‚¨** | Qdrant | é«˜æ•ˆç›¸ä¼¼åº¦æœç´¢ |
| **å…ƒæ•°æ®å­˜å‚¨** | PostgreSQL | æ–‡æ¡£å’Œå—çš„å…ƒæ•°æ® |
| **åµŒå…¥æœåŠ¡** | OpenAI Compatible API | ç”Ÿæˆå‘é‡ |
| **Agentæ¡†æ¶** | LangGraph | å¯¹è¯æµç¨‹ç¼–æ’ |
| **APIæ¡†æ¶** | FastAPI | HTTP æ¥å£ |
| **æ–‡æ¡£è§£æ** | pypdf, python-docx | å¤šæ ¼å¼æ”¯æŒ |

---

è¿™ä¸ªæ¶æ„å®ç°äº†ä¸€ä¸ª**ç”Ÿäº§çº§çš„ RAG ç³»ç»Ÿ**ï¼Œå…·å¤‡å®Œæ•´çš„æ–‡æ¡£ç®¡ç†ã€å‘é‡æ£€ç´¢å’Œå¯¹è¯å¢å¼ºèƒ½åŠ›ï¼ğŸ‰

