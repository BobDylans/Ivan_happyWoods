# LLM è°ƒç”¨é—®é¢˜ä¿®å¤

## ğŸ“… ä¿®å¤æ—¥æœŸ
2025-10-15

## ğŸ› é—®é¢˜æè¿°

æµ‹è¯•å¤šè½®å¯¹è¯æ—¶ï¼Œæ™ºèƒ½ä½“è¿”å›çš„æ˜¯é¢„è®¾çš„ fallback å›å¤ï¼š
```
(Fallback) I understand you said: 'æˆ‘å«å°æ˜ï¼Œä»Šå¹´18å²'
```

è¿™è¯´æ˜ LLM è°ƒç”¨å¤±è´¥ï¼Œä»£ç fallbackåˆ°äº†é¢„è®¾å›å¤é€»è¾‘ã€‚

## ğŸ” æ ¹æœ¬åŸå› 

### é—®é¢˜ 1: URL é‡å¤ `/v1`

åœ¨ `src/agent/nodes.py` ç¬¬ 335-337 è¡Œï¼ŒURL æ„å»ºé€»è¾‘æœ‰bugï¼š

**é”™è¯¯ä»£ç **:
```python
base = self.config.llm.base_url.rstrip('/')  # https://api.openai-proxy.org/v1
# ...
if not base.endswith('/v1') and '/v1/' not in base:
    base = base + '/v1'  # æ¡ä»¶å¤±è´¥ï¼Œä½†é€»è¾‘æœ‰é—®é¢˜
url = f"{base}/{endpoint}"  # æœ€ç»ˆ: https://api.openai-proxy.org/v1/v1/chat/completions
```

é—®é¢˜åœ¨äºæ¡ä»¶ `'/v1/' not in base` - å®ƒæ£€æŸ¥çš„æ˜¯ `/v1/` è€Œä¸æ˜¯ `/v1`ï¼ˆæœ«å°¾ï¼‰ã€‚

**å®é™…æƒ…å†µ**:
- é…ç½®: `https://api.openai-proxy.org/v1`
- `base.endswith('/v1')` â†’ True
- ä½†å®é™…æ„å»º URLæ—¶å¯èƒ½è¿˜æ˜¯ä¼šå‡ºé—®é¢˜

## âœ… ä¿®å¤æ–¹æ¡ˆ

### 1. ç®€åŒ– URL æ„å»ºé€»è¾‘

**ä¿®å¤åçš„ä»£ç **:
```python
# Build URL - handle both with and without /v1 in base_url
endpoint = "chat/completions"
base = self.config.llm.base_url.rstrip('/')

# Only add /v1 if it's not already there
if not base.endswith('/v1'):
    base = base + '/v1'

url = f"{base}/{endpoint}"

self.logger.debug(f"LLM call to: {url}")
```

**é¢„æœŸç»“æœ**:
- é…ç½® `https://api.openai-proxy.org/v1` â†’ URL: `https://api.openai-proxy.org/v1/chat/completions` âœ…
- é…ç½® `https://api.openai-proxy.org` â†’ URL: `https://api.openai-proxy.org/v1/chat/completions` âœ…

### 2. å¢å¼ºé”™è¯¯æ—¥å¿—

**æ·»åŠ çš„æ—¥å¿—**:
```python
# è¯·æ±‚å‰
self.logger.debug(f"LLM call to: {url}")

# å“åº”å
self.logger.debug(f"LLM response received: {len(data.get('choices', []))} choices")

# é”™è¯¯æ—¶
self.logger.error(f"LLM HTTP {resp.status_code}: {error_text}")
```

è¿™æ ·å¯ä»¥æ›´å®¹æ˜“è¯Šæ–­é—®é¢˜ã€‚

## ğŸ§ª éªŒè¯æ­¥éª¤

### 1. é‡å¯æœåŠ¡å™¨

```bash
# åœæ­¢å½“å‰æœåŠ¡
# Ctrl+C

# é‡æ–°å¯åŠ¨
python start_server.py
```

### 2. è¿è¡Œæµ‹è¯•

```bash
python test_conversation.py
```

### 3. æœŸå¾…çš„ç»“æœ

**æµ‹è¯• 5: å¤šè½®å¯¹è¯**

ç¬¬ä¸€è½®:
```
ç”¨æˆ·: æˆ‘å«å°æ˜ï¼Œä»Šå¹´18å²
æ™ºèƒ½ä½“: ä½ å¥½å°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ... ï¼ˆçœŸå®çš„LLMå›å¤ï¼Œä¸æ˜¯Fallbackï¼‰
```

ç¬¬äºŒè½®:
```
ç”¨æˆ·: ä½ è¿˜è®°å¾—æˆ‘å«ä»€ä¹ˆåå­—å—ï¼Ÿ
æ™ºèƒ½ä½“: å½“ç„¶è®°å¾—ï¼Œä½ å«å°æ˜ï¼ï¼ˆåº”è¯¥èƒ½è®°ä½ï¼‰
```

ç¬¬ä¸‰è½®:
```
ç”¨æˆ·: æˆ‘ä»Šå¹´å¤šå°‘å²äº†ï¼Ÿ
æ™ºèƒ½ä½“: ä½ ä»Šå¹´18å²ã€‚ï¼ˆåº”è¯¥èƒ½è®°ä½ï¼‰
```

### 4. æ£€æŸ¥æ—¥å¿—

å¯åŠ¨æœåŠ¡åï¼Œåº”è¯¥çœ‹åˆ°ï¼š
```
INFO - LLM call to: https://api.openai-proxy.org/v1/chat/completions
DEBUG - LLM response received: 1 choices
```

å¦‚æœè¿˜æœ‰é—®é¢˜ï¼Œä¼šçœ‹åˆ°ï¼š
```
ERROR - LLM HTTP 401: {"error": "Invalid API key"}
```
æˆ–
```
ERROR - LLM HTTP 404: Not found
```

## ğŸ” å…¶ä»–å¯èƒ½çš„é—®é¢˜

### é—®é¢˜ 1: API Key æ— æ•ˆ

**ç—‡çŠ¶**: HTTP 401 é”™è¯¯

**è§£å†³**: æ£€æŸ¥ `.env` æ–‡ä»¶ä¸­çš„ API Key:
```bash
VOICE_AGENT_LLM__API_KEY=sk-M9DIQm5fQ66GgUtCXe9jw1MjjsPlNgSXF38gHQStYkIxan30
```

éªŒè¯ API Key æ˜¯å¦æœ‰æ•ˆã€‚

### é—®é¢˜ 2: ç½‘ç»œè¿æ¥é—®é¢˜

**ç—‡çŠ¶**: Timeout æˆ– Connection error

**è§£å†³**: 
- æ£€æŸ¥ç½‘ç»œè¿æ¥
- å°è¯•è®¿é—® https://api.openai-proxy.org
- å¢åŠ è¶…æ—¶æ—¶é—´: `VOICE_AGENT_LLM__TIMEOUT=60`

### é—®é¢˜ 3: Base URL é”™è¯¯

**ç—‡çŠ¶**: HTTP 404 Not Found

**è§£å†³**: ç¡®è®¤ Base URL æ­£ç¡®:
```bash
VOICE_AGENT_LLM__BASE_URL=https://api.openai-proxy.org/v1
```

### é—®é¢˜ 4: æ¨¡å‹ä¸å¯ç”¨

**ç—‡çŠ¶**: HTTP 400 "Model not found"

**è§£å†³**: æ£€æŸ¥æ¨¡å‹åç§°:
```bash
VOICE_AGENT_LLM__MODELS__DEFAULT=gpt-5-pro
```

ç¡®è®¤è¯¥æ¨¡å‹åœ¨APIæä¾›å•†å¤„å¯ç”¨ã€‚

## ğŸ“ æµ‹è¯•æ¸…å•

è¿è¡Œæµ‹è¯•åï¼Œæ£€æŸ¥ä»¥ä¸‹é¡¹ï¼š

- [ ] æœåŠ¡å™¨æˆåŠŸå¯åŠ¨
- [ ] æ²¡æœ‰ LLM åˆå§‹åŒ–é”™è¯¯
- [ ] æµ‹è¯• 1ï¼ˆæ–‡æœ¬å¯¹è¯ï¼‰è¿”å›çœŸå®çš„LLMå›å¤ï¼Œä¸æ˜¯ "(Fallback)"
- [ ] æµ‹è¯• 5ï¼ˆå¤šè½®å¯¹è¯ï¼‰æ™ºèƒ½ä½“èƒ½è®°ä½ç”¨æˆ·ä¿¡æ¯
- [ ] æ—¥å¿—ä¸­çœ‹åˆ°æˆåŠŸçš„ HTTP è¯·æ±‚
- [ ] æ²¡æœ‰ HTTP 4xx/5xx é”™è¯¯

## ğŸš€ ä¸‹ä¸€æ­¥

å¦‚æœè¿™ä¸ªä¿®å¤åè¿˜æœ‰é—®é¢˜ï¼š

1. **æŸ¥çœ‹å®Œæ•´æ—¥å¿—**: å¯åŠ¨æœåŠ¡æ—¶è®¾ç½® `VOICE_AGENT_LOG_LEVEL=DEBUG`

2. **æ‰‹åŠ¨æµ‹è¯• API**:
   ```bash
   curl -X POST "https://api.openai-proxy.org/v1/chat/completions" \
        -H "Content-Type: application/json" \
        -H "Authorization: Bearer sk-M9DIQm5fQ66GgUtCXe9jw1MjjsPlNgSXF38gHQStYkIxan30" \
        -d '{
          "model": "gpt-5-pro",
          "messages": [{"role": "user", "content": "ä½ å¥½"}]
        }'
   ```

3. **æ£€æŸ¥ HTTP å®¢æˆ·ç«¯åˆå§‹åŒ–**: ç¡®ä¿ httpx æ­£ç¡®é…ç½®

## ğŸ“Š é¢„æœŸ vs å®é™…

| åœºæ™¯ | ä¿®å¤å‰ | ä¿®å¤å |
|------|-------|--------|
| LLM è°ƒç”¨ | âŒ Fallback å›å¤ | âœ… çœŸå® LLM å›å¤ |
| URL | /v1/v1/chat/... (é”™è¯¯) | /v1/chat/... (æ­£ç¡®) |
| å¤šè½®å¯¹è¯ | âŒ ä¸è®°å¾— | âœ… è®°ä½ç”¨æˆ·ä¿¡æ¯ |
| é”™è¯¯æ—¥å¿— | ä¸æ˜ç¡® | âœ… æ¸…æ™°è¯¦ç»† |

---

**ä¿®å¤äºº**: GitHub Copilot  
**ä¿®å¤æ—¶é—´**: 2025-10-15  
**å½±å“æ–‡ä»¶**: `src/agent/nodes.py`  
**éªŒè¯çŠ¶æ€**: ğŸ”„ ç­‰å¾…æµ‹è¯•éªŒè¯
