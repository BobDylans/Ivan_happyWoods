# Ollama æœ¬åœ°å¤§æ¨¡å‹é›†æˆ - å¿«é€Ÿå‚è€ƒ

## ğŸ¯ ä¸€é”®å¯åŠ¨

```bash
# æ­¥éª¤ 1: å¯åŠ¨ Ollama
ollama serve

# æ­¥éª¤ 2: ä¸‹è½½æ¨¡å‹ (æ–°ç»ˆç«¯)
ollama pull qwen2.5:latest

# æ­¥éª¤ 3: å¯åŠ¨æœåŠ¡ (æ–°ç»ˆç«¯)
cd d:\Projects\ivanHappyWoods\backEnd
$env:VOICE_AGENT_ENVIRONMENT="ollama"; python start_server.py

# æ­¥éª¤ 4: è¿è¡Œæµ‹è¯• (æ–°ç»ˆç«¯)
python test_ollama_integration.py
```

---

## âœ… å®Œæˆçš„å·¥ä½œ

### 1. é…ç½®æ–‡ä»¶
- âœ… **config/ollama.yaml** - Ollama ä¸“ç”¨é…ç½®æ–‡ä»¶
  - é…ç½® Ollama API åœ°å€: `http://localhost:11434/v1`
  - é»˜è®¤æ¨¡å‹: `qwen2.5:latest`
  - å¢åŠ è¶…æ—¶æ—¶é—´: 60 ç§’(é€‚åº”æœ¬åœ°æ¨ç†)
  - ä¿ç•™æ•°æ®åº“æŒä¹…åŒ–é…ç½®

### 2. ä»£ç æ›´æ–°
- âœ… **src/utils/llm_compat.py** - æ·»åŠ  Ollama æ¨¡å‹æ”¯æŒ
  - æ·»åŠ  6 ä¸ª Ollama æ¨¡å‹ç‰¹æ€§æ˜ å°„:
    - `qwen2.5` (ä¸­æ–‡å¯¹è¯ä¼˜å…ˆ)
    - `qwen2` (ä¸­æ–‡å¯¹è¯)
    - `llama3.2` (å¿«é€Ÿæ¨ç†)
    - `llama3.1` (å¤§ä¸Šä¸‹æ–‡)
    - `mistral` (å¹³è¡¡æ€§èƒ½)
    - `deepseek-coder` (ä»£ç ç”Ÿæˆ)
  
  - æ›´æ–° `get_model_features()` å‡½æ•°:
    - æ”¯æŒ Ollama æ¨¡å‹æ ‡ç­¾æ ¼å¼ (å¦‚ `qwen2.5:latest`)
    - è‡ªåŠ¨å‰¥ç¦»æ ‡ç­¾ååŒ¹é…åŸºç¡€æ¨¡å‹å
    - é€»è¾‘: `qwen2.5:latest` â†’ å°è¯• `qwen2.5` â†’ åŒ¹é…æˆåŠŸ

### 3. æµ‹è¯•è„šæœ¬
- âœ… **test_ollama_integration.py** - å…¨é¢é›†æˆæµ‹è¯•
  - æ£€æŸ¥ Ollama æœåŠ¡çŠ¶æ€
  - æ£€æŸ¥åç«¯æœåŠ¡çŠ¶æ€
  - æµ‹è¯•ç®€å•å¯¹è¯åŠŸèƒ½
  - æµ‹è¯•æŒä¹…åŒ–å’Œä¸Šä¸‹æ–‡è®°å¿†
  - æµ‹è¯•æµå¼å“åº”
  - å½©è‰²è¾“å‡ºå’Œè¯¦ç»†æŠ¥å‘Š

### 4. æ–‡æ¡£
- âœ… **README_OLLAMA.md** - å®Œæ•´ä½¿ç”¨æŒ‡å—
  - å®‰è£…æ­¥éª¤(Windows/Linux/macOS)
  - æ¨¡å‹ä¸‹è½½å’Œç®¡ç†
  - é…ç½®è¯´æ˜
  - å¯åŠ¨æµç¨‹
  - æµ‹è¯•éªŒè¯æ–¹æ³•
  - æ•…éšœæ’æŸ¥æ¸…å•
  - æ€§èƒ½ä¼˜åŒ–å»ºè®®
  - å¸¸è§é—®é¢˜è§£ç­”

---

## ğŸ“š æ”¯æŒçš„ Ollama æ¨¡å‹

| æ¨¡å‹ | å¤§å° | ç”¨é€” | ä¸Šä¸‹æ–‡é•¿åº¦ | å‡½æ•°è°ƒç”¨ |
|------|------|------|-----------|---------|
| qwen2.5 | ~4.7GB | ä¸­æ–‡å¯¹è¯(æ¨è) | 32K | âœ… |
| llama3.2 | ~2GB | å¿«é€Ÿå“åº” | 8K | âœ… |
| llama3.1 | ~4.7GB | å¤§ä¸Šä¸‹æ–‡ | 128K | âœ… |
| mistral | ~4.1GB | å¹³è¡¡æ€§èƒ½ | 32K | âœ… |
| deepseek-coder | ~3.8GB | ä»£ç ç”Ÿæˆ | 16K | âœ… |
| qwen2 | ~4.7GB | ä¸­æ–‡å¯¹è¯ | 32K | âœ… |

---

## ğŸ”§ æ ¸å¿ƒæŠ€æœ¯å®ç°

### æ¨¡å‹åç§°åŒ¹é…é€»è¾‘

```python
def get_model_features(model: str) -> Dict[str, Any]:
    # 1. ç²¾ç¡®åŒ¹é…
    if model in MODEL_FEATURES:
        return MODEL_FEATURES[model]
    
    # 2. Ollama æ ‡ç­¾å‰¥ç¦» (NEW!)
    if ':' in model:
        base_model = model.split(':')[0]
        if base_model in MODEL_FEATURES:
            return MODEL_FEATURES[base_model]
    
    # 3. å‰ç¼€åŒ¹é…
    for model_prefix, features in MODEL_FEATURES.items():
        if model.startswith(model_prefix):
            return features
    
    # 4. é»˜è®¤ç‰¹æ€§
    return default_features
```

**æ”¯æŒçš„æ ¼å¼**:
- âœ… `qwen2.5` - åŸºç¡€åç§°
- âœ… `qwen2.5:latest` - å¸¦æ ‡ç­¾
- âœ… `qwen2.5:7b` - å¸¦å‚æ•°é‡
- âœ… `llama3.1:8b-instruct-fp16` - å®Œæ•´æ ‡ç­¾

### Ollama API å…¼å®¹æ€§

**OpenAI-Compatible ç«¯ç‚¹**:
- Ollama æä¾› `/v1/chat/completions` ç«¯ç‚¹
- ä¸ OpenAI API æ ¼å¼å…¼å®¹
- æ— éœ€ä¿®æ”¹ç°æœ‰ä»£ç ,åªéœ€æ›´æ”¹ `base_url`

**å‚æ•°å·®å¼‚**:
- âœ… Ollama ä½¿ç”¨æ ‡å‡† `max_tokens` (ä¸æ˜¯ `max_completion_tokens`)
- âœ… æ”¯æŒ `temperature` å‚æ•°
- âœ… æ”¯æŒ `stream` æµå¼å“åº”
- âœ… æ— éœ€ `api_key` (ç•™ç©ºå³å¯)

---

## ğŸš€ ä½¿ç”¨åœºæ™¯

### 1. å®Œå…¨ç¦»çº¿éƒ¨ç½²
```yaml
# config/offline.yaml
llm:
  provider: "ollama"
  base_url: "http://localhost:11434/v1"
  api_key: ""
  models:
    default: "qwen2.5:latest"

speech:
  tts:
    provider: "offline"  # æœªæ¥é›†æˆæœ¬åœ° TTS
  stt:
    provider: "offline"  # æœªæ¥é›†æˆæœ¬åœ° STT
```

### 2. æ··åˆéƒ¨ç½²
```yaml
# config/hybrid.yaml
llm:
  provider: "ollama"  # æœ¬åœ°æ¨ç†
  models:
    default: "qwen2.5:latest"

speech:
  tts:
    provider: "iflytek"  # äº‘ç«¯ TTS
  stt:
    provider: "iflytek"  # äº‘ç«¯ STT
```

### 3. å¼€å‘æµ‹è¯•
```bash
# æœ¬åœ°æµ‹è¯•æ—¶ä½¿ç”¨ Ollama (å…è´¹)
$env:VOICE_AGENT_ENVIRONMENT="ollama"
python start_server.py

# ç”Ÿäº§ç¯å¢ƒä½¿ç”¨äº‘ç«¯ API
$env:VOICE_AGENT_ENVIRONMENT="production"
python start_server.py
```

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

| æŒ‡æ ‡ | äº‘ç«¯ API (OpenAI) | æœ¬åœ° Ollama (CPU) | æœ¬åœ° Ollama (GPU) |
|------|------------------|-------------------|-------------------|
| **é¦–æ¬¡å“åº”** | ~600ms | ~3-5s | ~800ms-1.5s |
| **æµå¼å»¶è¿Ÿ** | ä½ | ä¸­ | ä½ |
| **æˆæœ¬** | æŒ‰ token è®¡è´¹ | å…è´¹ | å…è´¹ |
| **éšç§** | æ•°æ®ä¸Šäº‘ | å®Œå…¨æœ¬åœ° | å®Œå…¨æœ¬åœ° |
| **ç¨³å®šæ€§** | ä¾èµ–ç½‘ç»œ | æœ¬åœ°ç¨³å®š | æœ¬åœ°ç¨³å®š |
| **æ¨¡å‹é€‰æ‹©** | å—é™äºæä¾›å•† | ä»»æ„å¼€æºæ¨¡å‹ | ä»»æ„å¼€æºæ¨¡å‹ |

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### ç¡¬ä»¶è¦æ±‚
- **æœ€ä½**: 8GB RAM + 4 æ ¸ CPU
- **æ¨è**: 16GB RAM + 8 æ ¸ CPU + NVIDIA GPU (6GB+ VRAM)

### é¦–æ¬¡å¯åŠ¨
- ç¬¬ä¸€æ¬¡æ¨ç†ä¼šåŠ è½½æ¨¡å‹åˆ°å†…å­˜(~10-30ç§’)
- åç»­è¯·æ±‚ä¼šå¤ç”¨å·²åŠ è½½æ¨¡å‹(å“åº”æ›´å¿«)

### è¶…æ—¶è®¾ç½®
- Ollama æ¨ç†æ¯”äº‘ç«¯ API æ…¢
- å·²åœ¨é…ç½®ä¸­å¢åŠ è¶…æ—¶: 60 ç§’
- å¦‚æœä»è¶…æ—¶,å¯å¢åŠ åˆ° 120 ç§’

---

## ğŸ› æ•…éšœæ’æŸ¥

### é—®é¢˜ 1: Ollama æœåŠ¡æœªå¯åŠ¨
```bash
# é”™è¯¯: ConnectError: No connection could be made
# è§£å†³:
ollama serve
```

### é—®é¢˜ 2: æ¨¡å‹æœªä¸‹è½½
```bash
# é”™è¯¯: {"error": "model not found"}
# è§£å†³:
ollama pull qwen2.5:latest
```

### é—®é¢˜ 3: æ¨ç†è¶…æ—¶
```yaml
# ä¿®æ”¹ config/ollama.yaml
llm:
  timeout: 120  # å¢åŠ åˆ° 120 ç§’
```

### é—®é¢˜ 4: ä¸­æ–‡æ•ˆæœå·®
```bash
# ä½¿ç”¨ä¸­æ–‡ä¼˜åŒ–æ¨¡å‹
ollama pull qwen2.5:latest  # é˜¿é‡Œé€šä¹‰åƒé—®
```

---

## ğŸ“– è¯¦ç»†æ–‡æ¡£

- **å®Œæ•´æŒ‡å—**: [README_OLLAMA.md](./README_OLLAMA.md)
- **é¡¹ç›®æ–‡æ¡£**: [PROJECT.md](./PROJECT.md)
- **å¼€å‘æŒ‡å—**: [DEVELOPMENT.md](./DEVELOPMENT.md)

---

## âœ… éªŒè¯æ¸…å•

ä½¿ç”¨å‰è¯·ç¡®è®¤:

- [ ] Ollama å·²å®‰è£…: `ollama --version`
- [ ] Ollama æœåŠ¡è¿è¡Œ: `curl http://localhost:11434/api/tags`
- [ ] è‡³å°‘ä¸‹è½½ä¸€ä¸ªæ¨¡å‹: `ollama list`
- [ ] PostgreSQL è¿è¡Œ: `docker ps | findstr postgres`
- [ ] é…ç½®æ–‡ä»¶å­˜åœ¨: `config/ollama.yaml`
- [ ] ç¯å¢ƒå˜é‡æ­£ç¡®: `$env:VOICE_AGENT_ENVIRONMENT="ollama"`

**è¿è¡Œæµ‹è¯•**:
```bash
python test_ollama_integration.py
```

é¢„æœŸè¾“å‡º:
```
âœ… Ollama æœåŠ¡è¿è¡Œæ­£å¸¸
âœ… åç«¯æœåŠ¡è¿è¡Œæ­£å¸¸
âœ… å¯¹è¯æµ‹è¯•æˆåŠŸ
âœ… ä¸Šä¸‹æ–‡è®°å¿†æµ‹è¯•é€šè¿‡
âœ… æµå¼å“åº”æµ‹è¯•æˆåŠŸ
ğŸ‰ æ‰€æœ‰æ ¸å¿ƒæµ‹è¯•é€šè¿‡! Ollama é›†æˆæˆåŠŸ!
```

---

**çŠ¶æ€**: âœ… é›†æˆå®Œæˆ,å¾…ç”¨æˆ·æµ‹è¯•  
**ç‰ˆæœ¬**: 1.0  
**æ—¥æœŸ**: 2025-01-18  
**è´Ÿè´£äºº**: Ivan_HappyWoods Team
