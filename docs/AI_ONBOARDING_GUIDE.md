# AI Assistant ä¸Šæ‰‹æŒ‡å—

**é¡¹ç›®åç§°**: Ivan_HappyWoods - Voice-Based AI Agent Interaction System  
**ç›®æ ‡è¯»è€…**: AI Assistant (GitHub Copilot, Cursor, Claude, GPT-4, etc.)  
**ç‰ˆæœ¬**: 0.2.0-beta  
**æœ€åæ›´æ–°**: 2025-10-15

---

## ğŸ“Œ ç›®çš„

æœ¬æ–‡æ¡£æ—¨åœ¨å¸®åŠ© AI Assistant å¿«é€Ÿç†è§£ Ivan_HappyWoods é¡¹ç›®,ä½¿å…¶èƒ½å¤Ÿ:
1. âœ… å‡†ç¡®ç†è§£é¡¹ç›®å½“å‰çŠ¶æ€å’Œæ¶æ„
2. âœ… æä¾›ç¬¦åˆé¡¹ç›®è§„èŒƒçš„ä»£ç å»ºè®®
3. âœ… å¿«é€Ÿå®šä½ç›¸å…³æ–‡æ¡£å’Œä»£ç 
4. âœ… éµå¾ªé¡¹ç›®çš„å¼€å‘çº¦å®šå’Œæœ€ä½³å®è·µ

---

## ğŸš€ ç¬¬ä¸€æ­¥: å¿«é€Ÿä¸Šä¸‹æ–‡åˆ·æ–° (5åˆ†é’Ÿ)

### å¿…è¯»æ–‡æ¡£é¡ºåº

```
1. PROJECT.md (5åˆ†é’Ÿ) â­â­â­â­â­
   â””â”€ é‡ç‚¹é˜…è¯»: "Copilot Context Refresh" ç« èŠ‚
   â””â”€ å†…å®¹: å®Œæ•´æ¶æ„ã€æŠ€æœ¯æ ˆã€å½“å‰çŠ¶æ€

2. progress.md (3åˆ†é’Ÿ) â­â­â­â­
   â””â”€ ä½ç½®: specs/001-voice-interaction-system/progress.md
   â””â”€ å†…å®¹: è¯¦ç»†è¿›åº¦ã€å·²å®Œæˆ/è¿›è¡Œä¸­ä»»åŠ¡

3. CHANGELOG.md (2åˆ†é’Ÿ) â­â­â­
   â””â”€ å†…å®¹: æœ€è¿‘å˜æ›´ã€ç‰ˆæœ¬å†å²

4. .github/copilot-instructions.md (2åˆ†é’Ÿ) â­â­â­â­â­
   â””â”€ å†…å®¹: ä»£ç çº¦å®šã€ç‰¹æ®Šå¤„ç†é€»è¾‘
```

**æ€»æ—¶é—´**: çº¦ 12 åˆ†é’Ÿå³å¯æŒæ¡ 80% é¡¹ç›®ä¸Šä¸‹æ–‡

---

## ğŸ“Š ç¬¬äºŒæ­¥: ç†è§£é¡¹ç›®çŠ¶æ€ (å½“å‰å¿«ç…§)

### é¡¹ç›®æ€»ä½“çŠ¶æ€

```
å½“å‰ç‰ˆæœ¬: v0.2.0-beta
å¼€å‘é˜¶æ®µ: Phase 2 Complete (80% Overall)
æœ€åæ›´æ–°: 2025-10-15

Phase 1 (Core Foundation)        â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100% âœ…
Phase 2A (Voice Integration)     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100% âœ…
Phase 2B (Streaming TTS)         â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100% âœ…
Phase 2C (Conversation API)      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100% âœ…
Phase 2D (Code Optimization)     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100% âœ…
Phase 2E (MCP Tools)             â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘   0% â³
Phase 3 (Production Ready)       â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘   0% ğŸ“‹
```

### å½“å‰èƒ½åŠ›çŸ©é˜µ

| åŠŸèƒ½ | çŠ¶æ€ | å¯ç”¨æ€§ | å¤‡æ³¨ |
|------|------|--------|------|
| æ–‡æœ¬å¯¹è¯ | âœ… | ç”Ÿäº§å¯ç”¨ | éæµå¼ + SSE + WebSocket |
| è¯­éŸ³è¯†åˆ« (STT) | âœ… | ç”Ÿäº§å¯ç”¨ | iFlytek WebSocket |
| è¯­éŸ³åˆæˆ (TTS) | âœ… | ç”Ÿäº§å¯ç”¨ | <500ms TTFB, æµå¼ |
| ä¼šè¯ç®¡ç† | âœ… | å¼€å‘å¯ç”¨ | å†…å­˜å­˜å‚¨, é‡å¯ä¸¢å¤± |
| æµå¼å“åº” | âœ… | ç”Ÿäº§å¯ç”¨ | SSE + WebSocket |
| API è®¤è¯ | âœ… | ç”Ÿäº§å¯ç”¨ | API Key |
| å¯¹è¯å†å² | âœ… | ç”Ÿäº§å¯ç”¨ | æŸ¥è¯¢ + æ¸…é™¤ API |
| MCP å·¥å…· | â³ | æœªå®ç° | Phase 2E è§„åˆ’ä¸­ |
| Redis å­˜å‚¨ | ğŸ“‹ | æœªå®ç° | Phase 3 è§„åˆ’ä¸­ |
| å®¹å™¨åŒ– | ğŸ“‹ | æœªå®ç° | Phase 3 è§„åˆ’ä¸­ |

### å…³é”®å†³ç­–ç‚¹ (AI å¿…çŸ¥)

1. **è¯­éŸ³æœåŠ¡**: ä½¿ç”¨ iFlytek (ç§‘å¤§è®¯é£), é OpenAI Whisper
   - åŸå› : ä¸­æ–‡ä¼˜åŒ–ã€ä½å»¶è¿Ÿã€æˆæœ¬ä¼˜åŠ¿
   - ä½ç½®: `src/services/voice/`

2. **ä¼šè¯å­˜å‚¨**: å†…å­˜ (LangGraph MemorySaver), éæ•°æ®åº“
   - åŸå› : MVP ç®€åŒ–å¼€å‘
   - é™åˆ¶: é‡å¯ä¸¢å¤±æ•°æ®
   - è¿ç§»è®¡åˆ’: Phase 3 Redis

3. **LLM å…¼å®¹æ€§**: OpenAI-compatible, å½“å‰ gpt-5-mini
   - ç‰¹æ®Šå¤„ç†: GPT-5 ç³»åˆ—ä¸æ”¯æŒ temperature å‚æ•°
   - ä½ç½®: `src/utils/llm_compat.py`

4. **ä»£ç æœ¬åœ°åŒ–**: ä¸­æ–‡æ³¨é‡Šã€é”™è¯¯æ¶ˆæ¯ã€æ—¥å¿—
   - åŸå› : ç”¨æˆ·ä½“éªŒ + å›¢é˜Ÿæ•ˆç‡
   - ä»£ç : è‹±æ–‡å˜é‡/å‡½æ•°å

5. **èµ„æºç®¡ç†**: Async context manager
   - æ¨¡å¼: `async with AgentNodes(...) as nodes:`
   - åŸå› : é˜²æ­¢ HTTP å®¢æˆ·ç«¯æ³„æ¼

---

## ğŸ—ï¸ ç¬¬ä¸‰æ­¥: æŒæ¡æ¶æ„ (æ ¸å¿ƒæ¦‚å¿µ)

### æ¶æ„å±‚æ¬¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Client Layer                â”‚
â”‚  (Web/Mobile/Voice Device)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ HTTP/WebSocket
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      FastAPI Gateway Layer          â”‚
â”‚  â€¢ REST API (conversation_routes)   â”‚
â”‚  â€¢ WebSocket (streaming)            â”‚
â”‚  â€¢ Middleware (CORS/Auth/Logging)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       Service Layer                 â”‚
â”‚  â€¢ ConversationService (ä¼šè¯ç®¡ç†)   â”‚
â”‚  â€¢ VoiceService (STT/TTS)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       Agent Core (LangGraph)        â”‚
â”‚  â€¢ VoiceAgent (graph.py)            â”‚
â”‚  â€¢ AgentNodes (nodes.py)            â”‚
â”‚  â€¢ AgentState (state.py)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
        â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   LLM API    â”‚ â”‚ Voice APIs   â”‚
â”‚ (OpenAI-     â”‚ â”‚  (iFlytek)   â”‚
â”‚  compatible) â”‚ â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### å¯¹è¯æµç¨‹ (AI å¿…é¡»ç†è§£)

```
ç”¨æˆ·è¾“å…¥ (æ–‡æœ¬/è¯­éŸ³)
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. process_input    â”‚ â† nodes.py::process_input()
â”‚    - éªŒè¯è¾“å…¥        â”‚
â”‚    - æ›´æ–°å†å²        â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. call_llm         â”‚ â† nodes.py::call_llm() / stream_llm_call()
â”‚    - æ„å»ºæç¤ºè¯      â”‚
â”‚    - è°ƒç”¨ LLM API   â”‚
â”‚    - å¤„ç†å“åº”        â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. handle_tools     â”‚ â† nodes.py::handle_tools() (æœªå®ç°)
â”‚    (Phase 2E)       â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. format_response  â”‚ â† nodes.py::format_response()
â”‚    - æ ¼å¼åŒ–è¾“å‡º      â”‚
â”‚    - æ›´æ–°çŠ¶æ€        â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. TTS (å¯é€‰)       â”‚ â† services/voice/tts_service.py
â”‚    - æ–‡æœ¬è½¬è¯­éŸ³      â”‚
â”‚    - æµå¼æ¨é€        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ ç¬¬å››æ­¥: ä»£ç å¯¼èˆªåœ°å›¾

### æ ¸å¿ƒæ–‡ä»¶æ¸…å• (AI åº”å½“ç†Ÿæ‚‰)

```
ğŸ”¥ è¶…é«˜é¢‘è®¿é—® (æ¯æ¬¡ä¿®æ”¹å¯¹è¯é€»è¾‘æ—¶)
â”œâ”€â”€ src/agent/graph.py (375 lines)
â”‚   â””â”€ VoiceAgent ç±», LangGraph å·¥ä½œæµå®šä¹‰
â”‚
â”œâ”€â”€ src/agent/nodes.py (768 lines) â­ æœ€é‡è¦
â”‚   â””â”€ AgentNodes ç±», æ‰€æœ‰å¤„ç†èŠ‚ç‚¹å®ç°
â”‚   â””â”€ process_input(), call_llm(), stream_llm_call(), 
â”‚       handle_tools(), format_response()
â”‚
â””â”€â”€ src/agent/state.py
    â””â”€ AgentState çŠ¶æ€æ¨¡å‹

ğŸ”¥ é«˜é¢‘è®¿é—® (API å¼€å‘æ—¶)
â”œâ”€â”€ src/api/conversation_routes.py
â”‚   â””â”€ å¯¹è¯ç«¯ç‚¹: /send, /stream, /history, /clear
â”‚
â”œâ”€â”€ src/api/voice_routes.py
â”‚   â””â”€ è¯­éŸ³ç«¯ç‚¹: /stt, /tts, /stream
â”‚
â””â”€â”€ src/api/main.py
    â””â”€ FastAPI åº”ç”¨å…¥å£

ğŸ”¥ ä¸­é¢‘è®¿é—® (é…ç½®/å·¥å…·æ—¶)
â”œâ”€â”€ src/config/models.py
â”‚   â””â”€ Pydantic é…ç½®æ¨¡å‹
â”‚
â”œâ”€â”€ src/utils/llm_compat.py â­ é‡è¦
â”‚   â””â”€ LLM å…¼å®¹å±‚ (GPT-5 å¤„ç†)
â”‚
â”œâ”€â”€ src/services/voice/stt_service.py
â”‚   â””â”€ iFlytek STT å®ç°
â”‚
â””â”€â”€ src/services/voice/tts_service.py
    â””â”€ iFlytek TTS å®ç°

ğŸ”¥ ä½é¢‘è®¿é—® (ä½†éœ€è¦çŸ¥é“å­˜åœ¨)
â”œâ”€â”€ src/api/middleware.py
â”‚   â””â”€ CORS, è®¤è¯, æ—¥å¿—ä¸­é—´ä»¶
â”‚
â”œâ”€â”€ src/api/auth.py
â”‚   â””â”€ API Key è®¤è¯é€»è¾‘
â”‚
â””â”€â”€ src/services/conversation_service.py
    â””â”€ ä¼šè¯ç®¡ç†æœåŠ¡
```

### æ–‡ä»¶èŒè´£é€ŸæŸ¥è¡¨

| æ–‡ä»¶ | èŒè´£ | ä½•æ—¶ä¿®æ”¹ |
|------|------|----------|
| `graph.py` | LangGraph å·¥ä½œæµç¼–æ’ | æ·»åŠ æ–°èŠ‚ç‚¹ã€ä¿®æ”¹è·¯ç”± |
| `nodes.py` | èŠ‚ç‚¹å®ç°é€»è¾‘ | ä¿®æ”¹å¯¹è¯å¤„ç†ã€LLM è°ƒç”¨ |
| `state.py` | çŠ¶æ€æ¨¡å‹å®šä¹‰ | æ·»åŠ æ–°çŠ¶æ€å­—æ®µ |
| `conversation_routes.py` | å¯¹è¯ API | æ·»åŠ æ–°ç«¯ç‚¹ã€ä¿®æ”¹è¯·æ±‚/å“åº” |
| `voice_routes.py` | è¯­éŸ³ API | ä¿®æ”¹ STT/TTS é€»è¾‘ |
| `llm_compat.py` | LLM å…¼å®¹æ€§å¤„ç† | æ·»åŠ æ–°æ¨¡å‹å…¼å®¹é€»è¾‘ |
| `models.py` | é…ç½®æ¨¡å‹ | æ·»åŠ æ–°é…ç½®é¡¹ |

---

## ğŸ¯ ç¬¬äº”æ­¥: ä»£ç çº¦å®š (AI å¿…é¡»éµå®ˆ)

### 1. å‘½åè§„èŒƒ

```python
# Classes: PascalCase
class VoiceAgent:
    pass

# Functions: snake_case
async def process_input(state: AgentState) -> AgentState:
    pass

# Constants: UPPER_SNAKE_CASE
MAX_HISTORY_MESSAGES = 10

# Private: _leading_underscore
def _ensure_http_client(self):
    pass
```

### 2. æ–‡æ¡£å­—ç¬¦ä¸² (å¿…é¡»ä¸­æ–‡)

```python
async def process_input(self, state: AgentState) -> AgentState:
    """
    å¤„ç†ç”¨æˆ·è¾“å…¥èŠ‚ç‚¹
    
    åŠŸèƒ½:
    1. éªŒè¯ç”¨æˆ·è¾“å…¥
    2. æ›´æ–°å¯¹è¯å†å²
    3. è®¾ç½®ä¸‹ä¸€ä¸ªèŠ‚ç‚¹
    
    Args:
        state: å½“å‰å¯¹è¯çŠ¶æ€
        
    Returns:
        æ›´æ–°åçš„çŠ¶æ€,åŒ…å« next_action å­—æ®µ
    """
    # å®ç°...
```

### 3. é”™è¯¯æ¶ˆæ¯ (å¿…é¡»ä¸­æ–‡)

```python
# âœ… æ­£ç¡®
raise ValueError("æŠ±æ­‰,å¤„ç†æ¶ˆæ¯æ—¶å‘ç”Ÿé”™è¯¯")
logger.error(f"LLM è°ƒç”¨å¤±è´¥: {str(e)}")

# âŒ é”™è¯¯
raise ValueError("Failed to process message")
logger.error(f"LLM call failed: {str(e)}")
```

### 4. æ—¥å¿—æ¶ˆæ¯ (å¿…é¡»ä¸­æ–‡)

```python
# âœ… æ­£ç¡®
self.logger.info(f"å¼€å§‹å¤„ç†ä¼šè¯: {session_id}")
self.logger.debug(f"LLM å“åº”: {response[:100]}")

# âŒ é”™è¯¯
self.logger.info(f"Processing session: {session_id}")
```

### 5. ä»£ç æ³¨é‡Š (å¯ä»¥è‹±æ–‡,æ¨èä¸­æ–‡)

```python
# âœ… æ¨è
# åˆå§‹åŒ– HTTP å®¢æˆ·ç«¯ (æ‡’åŠ è½½æ¨¡å¼)
await self._ensure_http_client()

# âœ… å¯æ¥å—
# Initialize HTTP client (lazy loading)
await self._ensure_http_client()
```

### 6. å˜é‡å’Œå‡½æ•°å (å¿…é¡»è‹±æ–‡)

```python
# âœ… æ­£ç¡®
user_input = state["user_input"]
session_id = state["session_id"]

# âŒ é”™è¯¯ (ä¸è¦ç”¨æ‹¼éŸ³)
yonghu_shuru = state["user_input"]
huihua_id = state["session_id"]
```

---

## ğŸ”§ ç¬¬å…­æ­¥: å¸¸è§æ¨¡å¼ (AI åº”æŒæ¡)

### æ¨¡å¼ 1: æ·»åŠ  LangGraph èŠ‚ç‚¹

```python
# æ­¥éª¤ 1: åœ¨ src/agent/nodes.py æ·»åŠ èŠ‚ç‚¹æ–¹æ³•
class AgentNodes:
    async def my_new_node(self, state: AgentState) -> AgentState:
        """
        æ–°èŠ‚ç‚¹åŠŸèƒ½æè¿°
        
        å¤„ç†é€»è¾‘:
        1. æ­¥éª¤ä¸€
        2. æ­¥éª¤äºŒ
        """
        # èŠ‚ç‚¹é€»è¾‘
        result = await self._process_something(state)
        
        # æ›´æ–°çŠ¶æ€
        state["my_field"] = result
        state["next_action"] = "next_node"
        
        return state

# æ­¥éª¤ 2: åœ¨ src/agent/graph.py æ³¨å†ŒèŠ‚ç‚¹
def _build_graph(self):
    workflow = StateGraph(AgentState)
    
    # æ³¨å†ŒèŠ‚ç‚¹
    workflow.add_node("my_new_node", self.nodes.my_new_node)
    
    # æ·»åŠ è¾¹
    workflow.add_edge("previous_node", "my_new_node")
    workflow.add_edge("my_new_node", "next_node")
    
    # æˆ–æ¡ä»¶è¾¹
    workflow.add_conditional_edges(
        "my_new_node",
        self._route_after_my_node,
        {
            "path_a": "node_a",
            "path_b": "node_b"
        }
    )
```

### æ¨¡å¼ 2: æ·»åŠ  API ç«¯ç‚¹

```python
# æ­¥éª¤ 1: åœ¨ src/api/models.py å®šä¹‰æ¨¡å‹
from pydantic import BaseModel

class MyRequest(BaseModel):
    session_id: str
    param: str

class MyResponse(BaseModel):
    result: str
    status: str

# æ­¥éª¤ 2: åœ¨ src/api/conversation_routes.py (æˆ–æ–°æ–‡ä»¶) å®ç°è·¯ç”±
from fastapi import APIRouter, HTTPException

router = APIRouter(prefix="/api/conversation", tags=["Conversation"])

@router.post("/my-endpoint", response_model=MyResponse)
async def my_endpoint(request: MyRequest):
    """
    ç«¯ç‚¹åŠŸèƒ½æè¿°
    
    Args:
        request: è¯·æ±‚å‚æ•°
        
    Returns:
        å¤„ç†ç»“æœ
    """
    try:
        # ä¸šåŠ¡é€»è¾‘
        result = await process_data(request.param)
        return MyResponse(result=result, status="success")
    except Exception as e:
        logger.error(f"å¤„ç†å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"å¤„ç†å¤±è´¥: {str(e)}")

# æ­¥éª¤ 3: åœ¨ src/api/main.py æ³¨å†Œè·¯ç”± (å¦‚æœæ˜¯æ–°æ–‡ä»¶)
from api.my_routes import router as my_router
app.include_router(my_router)
```

### æ¨¡å¼ 3: LLM è°ƒç”¨ (å…¼å®¹æ€§å¤„ç†)

```python
from src.utils.llm_compat import prepare_llm_params

async def call_llm(self, state: AgentState) -> AgentState:
    """è°ƒç”¨ LLM API"""
    
    # 1. æ„å»ºæ¶ˆæ¯
    messages = self._build_messages(state)
    
    # 2. å‡†å¤‡å‚æ•° (å¤„ç† GPT-5 å…¼å®¹æ€§)
    model = self.config.llm.models.default
    params = prepare_llm_params(
        model=model,
        messages=messages,
        temperature=0.7,  # GPT-5 ä¼šè‡ªåŠ¨ç§»é™¤
        max_tokens=2048
    )
    
    # 3. ç¡®ä¿ HTTP å®¢æˆ·ç«¯å·²åˆå§‹åŒ–
    await self._ensure_http_client()
    
    # 4. è°ƒç”¨ API
    url = self._build_llm_url()
    response = await self._http_client.post(
        url,
        json=params,
        headers={"Authorization": f"Bearer {api_key}"}
    )
    
    # 5. å¤„ç†å“åº”
    data = response.json()
    content = data["choices"][0]["message"]["content"]
    
    # 6. æ›´æ–°çŠ¶æ€
    state["llm_response"] = content
    state["next_action"] = "format_response"
    
    return state
```

### æ¨¡å¼ 4: èµ„æºç®¡ç† (å¿…é¡»ä½¿ç”¨)

```python
# âœ… æ¨è: ä½¿ç”¨ async context manager
from src.agent.nodes import AgentNodes

async def process_conversation(config):
    async with AgentNodes(config) as nodes:
        result = await nodes.process_input(state)
        # è‡ªåŠ¨æ¸…ç†èµ„æº
    
# âœ… å¯æ¥å—: æ‰‹åŠ¨æ¸…ç†
nodes = AgentNodes(config)
try:
    result = await nodes.process_input(state)
finally:
    await nodes.cleanup()

# âŒ é”™è¯¯: ä¸æ¸…ç†èµ„æº
nodes = AgentNodes(config)
result = await nodes.process_input(state)
# å¯èƒ½å¯¼è‡´ HTTP å®¢æˆ·ç«¯æ³„æ¼
```

### æ¨¡å¼ 5: æå–é‡å¤ä»£ç  (Extract Method)

```python
# âŒ é‡å¤ä»£ç 
async def method_a(self):
    if self._http_client is None:
        async with self._client_lock:
            if self._http_client is None:
                self._http_client = httpx.AsyncClient(timeout=30.0)
    # ä½¿ç”¨ self._http_client

async def method_b(self):
    if self._http_client is None:
        async with self._client_lock:
            if self._http_client is None:
                self._http_client = httpx.AsyncClient(timeout=30.0)
    # ä½¿ç”¨ self._http_client

# âœ… æå–æ–¹æ³•
async def _ensure_http_client(self):
    """ç¡®ä¿ HTTP å®¢æˆ·ç«¯å·²åˆå§‹åŒ– (æ‡’åŠ è½½)"""
    if self._http_client is None:
        async with self._client_lock:
            if self._http_client is None:
                self._http_client = httpx.AsyncClient(timeout=30.0)

async def method_a(self):
    await self._ensure_http_client()
    # ä½¿ç”¨ self._http_client

async def method_b(self):
    await self._ensure_http_client()
    # ä½¿ç”¨ self._http_client
```

---

## âš ï¸ ç¬¬ä¸ƒæ­¥: ç‰¹æ®Šæ³¨æ„äº‹é¡¹ (AI å¿…çŸ¥é™·é˜±)

### é™·é˜± 1: GPT-5 ç³»åˆ— temperature å‚æ•°

```python
# âŒ é”™è¯¯: ç›´æ¥ä¼ é€’ temperature ç»™ GPT-5
params = {
    "model": "gpt-5-mini",
    "temperature": 0.7,  # GPT-5 ä¸æ”¯æŒ!
    "messages": messages
}

# âœ… æ­£ç¡®: ä½¿ç”¨å…¼å®¹å±‚
from src.utils.llm_compat import prepare_llm_params

params = prepare_llm_params(
    model="gpt-5-mini",
    messages=messages,
    temperature=0.7  # è‡ªåŠ¨ç§»é™¤
)
```

**åŸç†**: `llm_compat.py` æ£€æµ‹ GPT-5 ç³»åˆ—,è‡ªåŠ¨ç§»é™¤ temperature å‚æ•°ã€‚

### é™·é˜± 2: ä¼šè¯æ•°æ®åœ¨é‡å¯åä¸¢å¤±

```python
# âš ï¸ å½“å‰é™åˆ¶: å†…å­˜å­˜å‚¨
# é—®é¢˜: æœåŠ¡é‡å¯åæ‰€æœ‰ä¼šè¯ä¸¢å¤±

# ä¸´æ—¶è§£å†³æ–¹æ¡ˆ: é¿å…é¢‘ç¹é‡å¯
# é•¿æœŸè®¡åˆ’: Phase 3 è¿ç§»åˆ° Redis
```

**æç¤º AI**: ä¸è¦å»ºè®®ç”¨æˆ·ä¾èµ–æŒä¹…åŒ–,æ˜ç¡®å‘ŠçŸ¥æ•°æ®ä¼šä¸¢å¤±ã€‚

### é™·é˜± 3: HTTP å®¢æˆ·ç«¯å¿…é¡»æ¸…ç†

```python
# âŒ é”™è¯¯: å¿˜è®°æ¸…ç†
class AgentNodes:
    def __init__(self, config):
        self._http_client = httpx.AsyncClient()
    
    # æ²¡æœ‰ cleanup æ–¹æ³• â†’ æ³„æ¼!

# âœ… æ­£ç¡®: å®ç°æ¸…ç†
class AgentNodes:
    def __init__(self, config):
        self._http_client = None
        self._client_lock = asyncio.Lock()
    
    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self._http_client:
            await self._http_client.aclose()
            self._http_client = None
    
    async def __aenter__(self):
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        await self.cleanup()
```

### é™·é˜± 4: å†å²æ¶ˆæ¯æ•°é‡é™åˆ¶

```python
# âš ï¸ æ³¨æ„: æœ‰æœ€å¤§å†å²æ¶ˆæ¯é™åˆ¶
MAX_HISTORY_MESSAGES = 10

# æç¤º AI: ä¸è¦å»ºè®®æ— é™å­˜å‚¨å†å²
# å½“å‰è®¾è®¡: åªä¿ç•™æœ€è¿‘ 10 æ¡æ¶ˆæ¯
```

### é™·é˜± 5: MCP å·¥å…·å°šæœªå®ç°

```python
# âš ï¸ å½“å‰çŠ¶æ€: handle_tools èŠ‚ç‚¹ä¸ºå ä½ç¬¦
async def handle_tools(self, state: AgentState) -> AgentState:
    """
    å·¥å…·è°ƒç”¨èŠ‚ç‚¹ (Phase 2E - æœªå®ç°)
    """
    # å½“å‰ç›´æ¥è·³è¿‡
    state["next_action"] = "format_response"
    return state

# æç¤º AI: ä¸è¦å»ºè®®ä½¿ç”¨å·¥å…·åŠŸèƒ½,æ˜ç¡®å‘ŠçŸ¥æœªå®ç°
```

---

## ğŸ§ª ç¬¬å…«æ­¥: æµ‹è¯•æŒ‡å¯¼

### è¿è¡Œæµ‹è¯•

```bash
# æ‰€æœ‰æµ‹è¯•
pytest

# ç‰¹å®šæ¨¡å—
pytest tests/unit/test_agent.py

# å¸¦è¦†ç›–ç‡
pytest --cov=src tests/

# ä»£ç è´¨é‡æ£€æŸ¥
ruff check src/
```

### ç¼–å†™æµ‹è¯• (AI åº”éµå¾ªçš„æ¨¡å¼)

```python
# tests/unit/test_my_feature.py
import pytest
from src.agent.nodes import AgentNodes
from src.agent.state import create_initial_state

@pytest.fixture
async def agent_nodes():
    """åˆ›å»º AgentNodes å®ä¾‹"""
    config = VoiceAgentConfig()
    nodes = AgentNodes(config)
    yield nodes
    await nodes.cleanup()  # é‡è¦: æ¸…ç†èµ„æº

@pytest.mark.asyncio
async def test_my_feature(agent_nodes):
    """
    æµ‹è¯•åŠŸèƒ½æè¿°
    
    æµ‹è¯•æ­¥éª¤:
    1. å‡†å¤‡æµ‹è¯•æ•°æ®
    2. è°ƒç”¨åŠŸèƒ½
    3. éªŒè¯ç»“æœ
    """
    # Arrange
    state = create_initial_state(
        session_id="test",
        user_input="æµ‹è¯•è¾“å…¥"
    )
    
    # Act
    result = await agent_nodes.my_method(state)
    
    # Assert
    assert result["expected_field"] == "expected_value"
    assert result["next_action"] == "next_node"
```

---

## ğŸ“š ç¬¬ä¹æ­¥: æ–‡æ¡£æŸ¥æ‰¾æŒ‡å—

### éœ€è¦æŸä¸ªä¿¡æ¯æ—¶,å»å“ªé‡Œæ‰¾?

| éœ€æ±‚ | æ–‡æ¡£ä½ç½® | ç« èŠ‚/å…³é”®è¯ |
|------|---------|------------|
| **é¡¹ç›®æ€»è§ˆ** | `PROJECT.md` | "Copilot Context Refresh" |
| **å½“å‰è¿›åº¦** | `specs/001-.../progress.md` | è¿›åº¦æ¦‚è§ˆã€Phase çŠ¶æ€ |
| **æœ€è¿‘å˜æ›´** | `CHANGELOG.md` | v0.2.0 ç« èŠ‚ |
| **å¿«é€Ÿä¸Šæ‰‹** | `DEVELOPMENT.md` | "10 åˆ†é’Ÿå¿«é€Ÿè®¾ç½®" |
| **API ä½¿ç”¨** | `specs/001-.../quickstart.md` | "Basic Usage" |
| **å¼€å‘æŠ¥å‘Š** | `docs/achievements/INDEX.md` | æŒ‰ Phase åˆ†ç±» |
| **ä»£ç çº¦å®š** | `.github/copilot-instructions.md` | "Code Conventions" |
| **æ¶æ„è®¾è®¡** | `PROJECT.md` | "å½“å‰æ¶æ„" ç« èŠ‚ |
| **æŠ€æœ¯å†³ç­–** | `PROJECT.md` | "å…³é”®æŠ€æœ¯å†³ç­–" |
| **å¸¸è§é—®é¢˜** | `PROJECT.md` æˆ– `DEVELOPMENT.md` | FAQ ç« èŠ‚ |
| **TTS ä½¿ç”¨** | `docs/achievements/phase2/TTS_QUICKSTART.md` | å®Œæ•´æŒ‡å— |
| **å¯¹è¯ API** | `docs/achievements/phase2/CONVERSATION_API_GUIDE.md` | API ç«¯ç‚¹ |
| **ä¼˜åŒ–æŠ¥å‘Š** | `docs/achievements/optimizations/CODE_OPTIMIZATION_COMPLETE.md` | ä¼˜åŒ–å†…å®¹ |
| **LLM ä¿®å¤** | `docs/achievements/reports/LLM_CALL_FIX.md` | GPT-5 å¤„ç† |

### å¿«é€Ÿæœç´¢æŠ€å·§

```bash
# åœ¨é¡¹ç›®ä¸­æœç´¢å…³é”®è¯
rg "å…³é”®è¯" --type py  # åªæœç´¢ Python æ–‡ä»¶
rg "å…³é”®è¯" docs/      # åªæœç´¢æ–‡æ¡£

# æŸ¥æ‰¾æ–‡ä»¶
fd "æ–‡ä»¶å"

# æŸ¥çœ‹ Git å†å²
git log --oneline --grep="å…³é”®è¯"
```

---

## ğŸ“ ç¬¬åæ­¥: AI è‡ªæ£€æ¸…å•

åœ¨æä¾›ä»£ç å»ºè®®å‰,AI åº”ç¡®è®¤:

### åŸºç¡€ç†è§£
- [ ] æˆ‘æ˜¯å¦ç†è§£å½“å‰é¡¹ç›®å¤„äº Phase 2 Complete (80%)?
- [ ] æˆ‘æ˜¯å¦çŸ¥é“ Phase 2E (MCP å·¥å…·) å°šæœªå®ç°?
- [ ] æˆ‘æ˜¯å¦ç†è§£ä¼šè¯å­˜å‚¨æ˜¯å†…å­˜,é‡å¯ä¸¢å¤±?

### ä»£ç è§„èŒƒ
- [ ] æˆ‘çš„æ–‡æ¡£å­—ç¬¦ä¸²æ˜¯å¦ä½¿ç”¨ä¸­æ–‡?
- [ ] æˆ‘çš„é”™è¯¯æ¶ˆæ¯æ˜¯å¦ä½¿ç”¨ä¸­æ–‡?
- [ ] æˆ‘çš„æ—¥å¿—æ¶ˆæ¯æ˜¯å¦ä½¿ç”¨ä¸­æ–‡?
- [ ] æˆ‘çš„å˜é‡/å‡½æ•°åæ˜¯å¦ä½¿ç”¨è‹±æ–‡?

### ç‰¹æ®Šå¤„ç†
- [ ] å¦‚æœæ¶‰åŠ LLM è°ƒç”¨,æˆ‘æ˜¯å¦ä½¿ç”¨äº† `llm_compat.py`?
- [ ] å¦‚æœæ¶‰åŠ HTTP å®¢æˆ·ç«¯,æˆ‘æ˜¯å¦ä½¿ç”¨äº† `_ensure_http_client()`?
- [ ] å¦‚æœåˆ›å»ºèµ„æº,æˆ‘æ˜¯å¦å®ç°äº† `cleanup()` æ–¹æ³•?
- [ ] å¦‚æœæ¶‰åŠ GPT-5,æˆ‘æ˜¯å¦é¿å…ä¼ é€’ temperature å‚æ•°?

### æ¶æ„ä¸€è‡´æ€§
- [ ] æˆ‘çš„ä»£ç æ˜¯å¦ç¬¦åˆåˆ†å±‚æ¶æ„ (API â†’ Service â†’ Agent)?
- [ ] æˆ‘çš„ LangGraph èŠ‚ç‚¹æ˜¯å¦è¿”å› `AgentState`?
- [ ] æˆ‘çš„èŠ‚ç‚¹æ˜¯å¦è®¾ç½®äº† `next_action` å­—æ®µ?
- [ ] æˆ‘çš„ API ç«¯ç‚¹æ˜¯å¦ä½¿ç”¨äº† Pydantic æ¨¡å‹?

### æœ€ä½³å®è·µ
- [ ] æˆ‘æ˜¯å¦æå–äº†é‡å¤ä»£ç  (Extract Method)?
- [ ] æˆ‘æ˜¯å¦ä½¿ç”¨äº† async/await (å¼‚æ­¥ç¼–ç¨‹)?
- [ ] æˆ‘æ˜¯å¦æ·»åŠ äº†é€‚å½“çš„é”™è¯¯å¤„ç†?
- [ ] æˆ‘æ˜¯å¦æ·»åŠ äº†å¿…è¦çš„æ—¥å¿—è®°å½•?

---

## ğŸš¨ å¸¸è§é”™è¯¯ç¤ºä¾‹ (AI åº”é¿å…)

### é”™è¯¯ 1: å»ºè®®ä½¿ç”¨æœªå®ç°çš„åŠŸèƒ½

```python
# âŒ AI ä¸åº”å»ºè®® (MCP å·¥å…·æœªå®ç°)
"ä½ å¯ä»¥ä½¿ç”¨ handle_tools èŠ‚ç‚¹æ¥è°ƒç”¨æœç´¢å·¥å…·..."

# âœ… AI åº”è¯¥è¯´
"æ³¨æ„: MCP å·¥å…·åŠŸèƒ½å°šæœªå®ç° (Phase 2E è§„åˆ’ä¸­)ã€‚
å½“å‰ handle_tools èŠ‚ç‚¹ä¸ºå ä½ç¬¦,ç›´æ¥è·³è¿‡åˆ° format_responseã€‚
å¦‚éœ€å·¥å…·åŠŸèƒ½,è¯·ç­‰å¾… Phase 2E å®æ–½ã€‚"
```

### é”™è¯¯ 2: å»ºè®®æŒä¹…åŒ–ä¼šè¯

```python
# âŒ AI ä¸åº”å»ºè®®
"ä½ å¯ä»¥åœ¨æ•°æ®åº“ä¸­æŒä¹…åŒ–ä¼šè¯æ•°æ®..."

# âœ… AI åº”è¯¥è¯´
"æ³¨æ„: å½“å‰ä½¿ç”¨å†…å­˜å­˜å‚¨ (LangGraph MemorySaver),
æœåŠ¡é‡å¯åä¼šè¯æ•°æ®ä¼šä¸¢å¤±ã€‚è¿™æ˜¯ MVP è®¾è®¡å†³ç­–,
æŒä¹…åŒ–å­˜å‚¨ (Redis) è®¡åˆ’åœ¨ Phase 3 å®æ–½ã€‚"
```

### é”™è¯¯ 3: å¿½ç•¥ GPT-5 å…¼å®¹æ€§

```python
# âŒ AI ä¸åº”å»ºè®®
params = {
    "model": "gpt-5-mini",
    "temperature": 0.7,
    "messages": messages
}

# âœ… AI åº”è¯¥å»ºè®®
from src.utils.llm_compat import prepare_llm_params

params = prepare_llm_params(
    model="gpt-5-mini",
    messages=messages,
    temperature=0.7  # è‡ªåŠ¨å¤„ç† GPT-5 å…¼å®¹æ€§
)
```

### é”™è¯¯ 4: è‹±æ–‡æ–‡æ¡£å­—ç¬¦ä¸²

```python
# âŒ AI ä¸åº”ç”Ÿæˆ
async def process_input(self, state: AgentState) -> AgentState:
    """
    Process user input and update conversation history.
    """
    pass

# âœ… AI åº”è¯¥ç”Ÿæˆ
async def process_input(self, state: AgentState) -> AgentState:
    """
    å¤„ç†ç”¨æˆ·è¾“å…¥å¹¶æ›´æ–°å¯¹è¯å†å²
    
    åŠŸèƒ½:
    1. éªŒè¯ç”¨æˆ·è¾“å…¥
    2. æ›´æ–°ä¼šè¯ä¸Šä¸‹æ–‡
    3. è®¾ç½®ä¸‹ä¸€ä¸ªå¤„ç†èŠ‚ç‚¹
    """
    pass
```

---

## ğŸ¯ æ€»ç»“: AI å¿«é€Ÿå‚è€ƒå¡

### 30 ç§’é€ŸæŸ¥

```
é¡¹ç›®: Voice-Based AI Agent (è¯­éŸ³ AI å¯¹è¯ç³»ç»Ÿ)
çŠ¶æ€: Phase 2 Complete (80%)
ç‰ˆæœ¬: v0.2.0-beta

æ ¸å¿ƒæ–‡ä»¶:
- src/agent/nodes.py (768è¡Œ) â† æœ€é‡è¦
- src/agent/graph.py (375è¡Œ)
- src/api/conversation_routes.py
- src/utils/llm_compat.py

å…³é”®çº¦å®š:
âœ… æ–‡æ¡£å­—ç¬¦ä¸²: ä¸­æ–‡
âœ… é”™è¯¯/æ—¥å¿—: ä¸­æ–‡
âœ… å˜é‡/å‡½æ•°: è‹±æ–‡
âœ… GPT-5: ä¸ä¼  temperature
âœ… èµ„æº: å¿…é¡» cleanup()

æœªå®ç°:
â³ MCP å·¥å…· (Phase 2E)
â³ Redis å­˜å‚¨ (Phase 3)
â³ Docker å®¹å™¨ (Phase 3)

å¿…è¯»æ–‡æ¡£:
1. PROJECT.md (Copilot Context Refresh)
2. progress.md (å½“å‰è¿›åº¦)
3. copilot-instructions.md (ä»£ç çº¦å®š)
```

---

## ğŸ“ éœ€è¦æ›´å¤šå¸®åŠ©?

- **é¡¹ç›®æ–‡æ¡£**: æŸ¥çœ‹ `docs/` ç›®å½•
- **API æ–‡æ¡£**: å¯åŠ¨æœåŠ¡åè®¿é—® http://localhost:8000/docs
- **å¼€å‘æŠ¥å‘Š**: `docs/achievements/INDEX.md`
- **å˜æ›´å†å²**: `CHANGELOG.md`

---

**ç¥ AI Assistant ä½¿ç”¨æ„‰å¿«!** ğŸ‰

*æœ¬æŒ‡å—ç”± Ivan_HappyWoods å›¢é˜Ÿç»´æŠ¤*  
*æœ€åæ›´æ–°: 2025-10-15*
